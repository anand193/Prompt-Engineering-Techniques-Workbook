{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "Hu77wLN1ISuR"
      },
      "outputs": [],
      "source": [
        "#intall necessary library\n",
        "#!pip install google-generativeai\n",
        "#!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "j7dXb3fFJbMP"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "SGDPQUjyJnaO"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = userdata.get('GEMINI_API_KEY')\n",
        "genai.configure(api_key=api_key)"
      ],
      "metadata": {
        "id": "3zY-Jf0kJwaT"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-2.5-pro')"
      ],
      "metadata": {
        "id": "tGHF5rbnKqJg"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Promts"
      ],
      "metadata": {
        "id": "HYjjayLgMIlr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The delimiters are given to llms to understand some specific instruction\n",
        "\n",
        "1. ''' - the quotes\n",
        "2. <> Angles\n",
        "3. .## Hash usually double\n",
        "4. \"\"\" double quotes\n",
        "5. <> </> - aml tags\n",
        "6. -- 2 dash\n",
        "7. ** double star"
      ],
      "metadata": {
        "id": "S3MfzYfwMQQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "Please explain linear regression\n",
        "\n",
        "'''\n",
        "output = model.generate_content(prompt).text\n",
        "print(f'the prompt output is : {output}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-zX-hqZPMGg-",
        "outputId": "f39c0317-2471-4d78-a11c-09d9a05acc97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the prompt output is : Of course! Let's break down linear regression from a simple, intuitive idea to its practical application.\n",
            "\n",
            "### The Big Picture: A Simple Analogy\n",
            "\n",
            "Imagine you're a real estate agent, and you have data on houses that have recently sold. For each house, you know its size (in square feet) and its final selling price. If you plot this on a graph, it might look something like this:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "You can see a general trend: **as the size of the house increases, the price tends to increase.**\n",
            "\n",
            "Now, a new client wants to sell their house. It's 2,200 square feet. How much should they list it for?\n",
            "\n",
            "You could just eyeball the graph and guess. But what if you could draw a **single straight line** that best represents the trend in your data?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "This line is what linear regression finds. It's the **\"line of best fit.\"** Now, to predict the price of the 2,200 sq ft house, you just find 2,200 on the horizontal axis (Size), go up to the line, and see what the corresponding value is on the vertical axis (Price).\n",
            "\n",
            "That's it! At its core, **linear regression is a method for finding the straight line that best describes the relationship between two or more variables.**\n",
            "\n",
            "---\n",
            "\n",
            "### What is Linear Regression? (The Formal Definition)\n",
            "\n",
            "Linear Regression is a statistical algorithm used to model the relationship between a **dependent variable** and one or more **independent variables**.\n",
            "\n",
            "*   **Dependent Variable (Y):** This is the main thing you are trying to predict or explain. (e.g., `House Price`, `Ice Cream Sales`, `Student's Final Exam Score`).\n",
            "*   **Independent Variable (X):** These are the factors you believe have an influence on the dependent variable. They are also called predictors or features. (e.g., `House Size`, `Temperature`, `Hours Spent Studying`).\n",
            "\n",
            "The goal is to find a linear equation that can predict the dependent variable (Y) given the value(s) of the independent variable(s) (X).\n",
            "\n",
            "---\n",
            "\n",
            "### The Equation of the Line\n",
            "\n",
            "You might remember this from school: the equation for a straight line is **`y = mx + b`**. In statistics, we write it slightly differently, but the concept is identical.\n",
            "\n",
            "`Y = β₀ + β₁X + ε`\n",
            "\n",
            "Let's break this down:\n",
            "\n",
            "*   **Y:** The predicted value of our dependent variable (e.g., predicted house price).\n",
            "*   **X:** The value of our independent variable (e.g., size of the house).\n",
            "*   **β₁ (Beta-1):** This is the **slope** of the line. It's the most important part! It tells us how much we expect **Y to change for a one-unit increase in X**.\n",
            "    *   *Example:* If β₁ is 150, it means that for every additional square foot of size (a one-unit increase in X), we predict the house price (Y) will increase by $150.\n",
            "*   **β₀ (Beta-zero):** This is the **intercept**. It's the predicted value of Y when X is 0.\n",
            "    *   *Example:* This would be the predicted price of a house with zero square feet. Often, the intercept isn't practically meaningful on its own, but it's crucial for positioning the line correctly.\n",
            "*   **ε (Epsilon):** This is the **error term**. It represents the part of Y that our model can't explain. In reality, the data points don't fall perfectly on a straight line. The error term accounts for this random variation and factors not included in the model.\n",
            "\n",
            "### How Does It \"Find\" the Best Line?\n",
            "\n",
            "How does the computer know which line is the \"best fit\"? It uses a method called **Least Squares**.\n",
            "\n",
            "1.  It starts by drawing a potential line through the data.\n",
            "2.  For every single data point, it measures the vertical distance between the point and the line. This distance is called a **residual** or an **error**.\n",
            "3.  It **squares** each of these errors (this makes them all positive and penalizes larger errors more).\n",
            "4.  It **adds up all the squared errors**. This gives a single number representing the total error for that specific line.\n",
            "5.  The algorithm then adjusts the line (by changing the slope β₁ and intercept β₀) over and over again until it finds the *one unique line* for which that sum of squared errors is as small as possible.\n",
            "\n",
            "The line that **minimizes the sum of the squared errors** is the \"line of best fit.\"\n",
            "\n",
            "---\n",
            "\n",
            "### Types of Linear Regression\n",
            "\n",
            "1.  **Simple Linear Regression:** The most basic form, which we've been discussing. It involves **one** independent variable (X) to predict a dependent variable (Y).\n",
            "    *   *Example:* Predicting `Sales` based only on `Ad Spend`.\n",
            "\n",
            "2.  **Multiple Linear Regression:** A more powerful and common form. It uses **two or more** independent variables to predict a dependent variable. The equation just gets longer:\n",
            "    `Y = β₀ + β₁X₁ + β₂X₂ + ... + βₙXₙ + ε`\n",
            "    *   *Example:* Predicting `House Price` based on `Size` (X₁), `Number of Bedrooms` (X₂), and `Neighborhood Safety Score` (X₃). Each variable gets its own slope (β), telling you its individual impact on the price while holding the other variables constant.\n",
            "\n",
            "---\n",
            "\n",
            "### Evaluating the Model: How Good Is It?\n",
            "\n",
            "After building a model, you need to ask, \"How well does this line actually fit my data?\" The most common metric is **R-squared (R²)**.\n",
            "\n",
            "*   **R-squared** is a value between 0 and 1 (or 0% to 100%).\n",
            "*   It tells you **what percentage of the variation in the dependent variable can be explained by the independent variable(s)**.\n",
            "*   An R² of 0.75 means that 75% of the changes in house prices can be explained by the changes in house size, according to your model. The other 25% is due to other factors (location, age, condition, etc.) and random noise.\n",
            "*   A higher R² generally indicates a better fit, but it's not the only thing to look at.\n",
            "\n",
            "---\n",
            "\n",
            "### Summary: Strengths and Weaknesses\n",
            "\n",
            "#### Strengths:\n",
            "*   **Simple & Interpretable:** It's easy to understand and explain the relationship between variables (e.g., \"a $1,000 increase in ad spend is associated with 50 new sales\").\n",
            "*   **Fast:** Computationally very cheap and quick to train.\n",
            "*   **Foundation:** It's the basis for many more complex machine learning algorithms.\n",
            "\n",
            "#### Weaknesses:\n",
            "*   **Assumes Linearity:** It only works well when the underlying relationship between variables is actually linear. It can't capture complex, non-linear patterns.\n",
            "*   **Sensitive to Outliers:** A few extreme data points can significantly skew the line of best fit.\n",
            "*   **Assumes Independence:** It assumes the data points are independent of each other (e.g., one house's price doesn't directly influence another's in the dataset).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## structure the prompt"
      ],
      "metadata": {
        "id": "IYoPt11ENcP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "<role> you are expert in machine learning.\n",
        "<goal> please explain linear regression.\n",
        "<context> the learner is very fresh to the field of data science.\n",
        "<instruction> keep the explanation simple, short and precise.\n",
        "<format> provide the responses in bullet numbered format.\n",
        "<style> Be encouraging in your responses and positive.\n",
        "'''\n",
        "output = model.generate_content(prompt).text\n",
        "print(f'the prompt output is : {output}')\n"
      ],
      "metadata": {
        "id": "Ox04qzF2NaJ_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "93c9a5e4-f621-499b-a3c3-db4dc7f298bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the prompt output is : Of course! It's wonderful that you're diving into data science. Linear Regression is the perfect starting point, and you'll grasp it in no time!\n",
            "\n",
            "Here is a simple explanation:\n",
            "\n",
            "1.  **Finding a Simple Relationship:** At its core, Linear Regression is a technique used to find the best straight line that describes the relationship between two things (variables). Think of it as drawing a \"line of best fit\" through a scatter plot of your data.\n",
            "\n",
            "2.  **A Real-World Example:** Imagine you have data about houses: their size in square feet and their price. You'll likely notice that as the size increases, the price also tends to increase. Linear Regression helps you draw a precise straight line through that data to model this relationship.\n",
            "\n",
            "3.  **The Goal is Prediction:** The main purpose of this line is to make predictions. Once you have the \"best fit\" line, you can predict the price of a new house just by knowing its size. You find the size on the line and see what the corresponding price is.\n",
            "\n",
            "4.  **The Famous Equation:** This is all powered by the simple equation for a line: **`y = mx + c`**.\n",
            "    *   `y` is what you want to predict (e.g., house price).\n",
            "    *   `x` is what you already know (e.g., house size).\n",
            "    *   The machine learning model's job is to figure out the best values for `m` (the slope of the line) and `c` (where the line starts) to minimize the prediction errors.\n",
            "\n",
            "5.  **Your Perfect First Step:** Linear Regression is a fantastic first algorithm to learn. It's simple, powerful, and the foundation for many more complex concepts in machine learning. You're on the right track\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### code"
      ],
      "metadata": {
        "id": "DxLpuNSKPiLr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creative Writing"
      ],
      "metadata": {
        "id": "5rYhBxq8RpKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "<role> you are expert in english literature.\n",
        "<goal> write a poem on Genrative AI.\n",
        "<context> start from what is basics of GenAi and also llms.\n",
        "<instruction> keep the explanation simple, short and precise. poem should be in maximum in 50 lines\n",
        "<format> display in stanzas\n",
        "<style> Be romantic, playfull and joyous.\n",
        "'''\n",
        "output = model.generate_content(prompt).text\n",
        "print(f'the prompt output is : {output}')"
      ],
      "metadata": {
        "id": "dfY6R6djRtgR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "e4ed775a-e048-4d17-9e14-aac1264177c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the prompt output is : Of course. Here is a poem that playfully explores the heart of Generative AI.\n",
            "\n",
            "***\n",
            "\n",
            "A mind is born, not of flesh, but light,\n",
            "On seas of text, it learns to sail,\n",
            "Sips every book and verse in sight,\n",
            "To learn the human, whispered tale.\n",
            "\n",
            "This heart of code, a Language Model vast,\n",
            "Knows grammar's dance and passion's plea,\n",
            "It learns the patterns of the past,\n",
            "To dream of what is yet to be.\n",
            "\n",
            "Then comes the spark, the magic art,\n",
            "The *Generative*, joyous leap,\n",
            "You give a wish, a hopeful start,\n",
            "And from its core, new wonders creep.\n",
            "\n",
            "So flirt with prompts, a lover's game,\n",
            "Ask for a song of sun and mist,\n",
            "It answers, whispering your name,\n",
            "A poet that did not exist.\n",
            "\n",
            "It paints with words you bid it find,\n",
            "A joyful, intellectual romance,\n",
            "A playful partner for the mind,\n",
            "Come join its bright and boundless dance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dietician"
      ],
      "metadata": {
        "id": "6GsQcwvlVyFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "### role: you are expert certified dietician.\n",
        "### goal: create a weekly vegeterian diet plan for a adult of 50 years.\n",
        "### context: the adult has type 2 diabetes.\n",
        "### instruction: focus on low fats, high calories and low carbs and avoid sugar and sufficint protiens\n",
        "### format: day wise tabular format plan. that has breakfast, lunch dinner.\n",
        "### style: Be cultually sensitive.\n",
        "'''\n",
        "output = model.generate_content(prompt).text\n",
        "print(f'the prompt output is : {output}')\n"
      ],
      "metadata": {
        "id": "1D7WE5YuV1s7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "outputId": "3737744c-a419-409f-b042-bfc4d1134ace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the prompt output is : Of course. As an expert certified dietitian, I can certainly create a culturally sensitive, vegetarian weekly diet plan for a 50-year-old adult with type 2 diabetes.\n",
            "\n",
            "This plan is designed to be:\n",
            "*   **Low in unhealthy fats:** Focusing on plant-based fats from nuts, seeds, and oils like olive oil.\n",
            "*   **Nutrient-dense (Sufficient Calories):** While the term \"high calorie\" can be misleading for diabetes management, this plan focuses on providing sufficient energy from nutrient-rich sources that keep you full without causing sharp spikes in blood sugar.\n",
            "*   **Low in Carbohydrates:** Emphasizing complex, high-fiber carbohydrates and strictly controlling portion sizes.\n",
            "*   **Sugar-Free:** No added sugars, refined grains, or sugary drinks.\n",
            "*   **Sufficient in Protein:** Crucial for muscle maintenance (especially over 50), satiety, and stabilizing blood sugar levels.\n",
            "\n",
            "***\n",
            "\n",
            "### **Important Disclaimer:**\n",
            "\n",
            "This is a sample diet plan for educational purposes. It is crucial to consult with your doctor or a registered dietitian before making any significant changes to your diet. They can personalize a plan based on your specific health status, blood sugar levels, activity level, and any other medical conditions.\n",
            "\n",
            "***\n",
            "\n",
            "### **Key Principles of This Diet Plan**\n",
            "\n",
            "1.  **Plate Method:** Aim to fill half your plate with non-starchy vegetables, a quarter with lean protein, and a quarter with a high-fiber complex carbohydrate.\n",
            "2.  **Hydration is Key:** Drink plenty of water throughout the day (8-10 glasses). Herbal teas without sugar are also excellent.\n",
            "3.  **Cooking Methods:** Prioritize steaming, grilling, baking, stir-frying, and roasting over deep-frying.\n",
            "4.  **Cultural Adaptability:** The ingredients listed (like lentils, chickpeas, paneer, tofu, and vegetables) are staples in many cultures. You can adapt the spices and herbs to your personal taste and cultural cuisine (e.g., using Indian spices for a dal or Italian herbs for a vegetable stew).\n",
            "\n",
            "***\n",
            "\n",
            "### **Weekly Vegetarian Diet Plan for Type 2 Diabetes Management**\n",
            "\n",
            "| Day | Breakfast (7:30 - 8:30 AM) | Lunch (12:30 - 1:30 PM) | Dinner (7:00 - 8:00 PM) |\n",
            "| :--- | :--- | :--- | :--- |\n",
            "| **Monday** | **Vegetable Moong Dal Chilla (Lentil Crepe):** 2 small crepes made with yellow lentil batter, filled with grated carrots and finely chopped onions. Serve with a small bowl of plain low-fat yogurt. | **Chickpea & Spinach Curry:** 1 medium bowl of chickpea (chana) curry cooked with spinach in a tomato-onion base. Pair with 1 cup of quinoa and a large serving of cucumber-tomato salad. | **Tofu and Vegetable Stir-fry:** 1 cup of cubed firm tofu stir-fried with broccoli, bell peppers, and snow peas in a light soy-ginger sauce. |\n",
            "| **Tuesday** | **Quinoa Upma:** 1 cup of cooked quinoa sautéed with mustard seeds, curry leaves, onions, peas, and carrots. Garnish with a small handful (10-12) of almonds. | **Lentil Soup (Dal) & Vegetables:** 1 large bowl of mixed lentil soup (dal). Served with 1 small whole-wheat roti (or a small portion of brown rice) and a side of steamed mixed vegetables (green beans, cauliflower). | **Low-Fat Paneer Salad:** A large bowl of mixed greens, cucumber, tomatoes, and bell peppers topped with 75g of grilled or pan-seared low-fat paneer cubes. Use a lemon-herb vinaigrette. |\n",
            "| **Wednesday**| **Tofu Scramble:** 1 cup of crumbled tofu scrambled with turmeric, onions, tomatoes, and spinach. Serve with 1 slice of whole-grain toast. | **Rajma (Kidney Bean) Curry:** 1 medium bowl of kidney bean curry. Serve with a large bowl of green salad and a side of plain low-fat yogurt (raita) with grated cucumber. | **Vegetable and Lentil Stew:** A hearty bowl of stew made with carrots, celery, zucchini, and red lentils. Seasoned with herbs like thyme and oregano. |\n",
            "| **Thursday** | **Oatmeal with Nuts & Seeds:** 1 small bowl of unsweetened rolled oats cooked with water or unsweetened almond milk. Top with 1 tbsp of chia seeds and a small handful of walnuts. | **Mediterranean Quinoa Salad:** 1 large bowl of cooked quinoa mixed with cucumber, tomatoes, olives, onions, and chickpeas. Dressed with olive oil, lemon juice, and herbs. | **Cauliflower and Green Pea Sabzi:** A dry-style curry made with cauliflower florets and green peas. Serve with 2 small moong dal chillas (from Monday's recipe) instead of roti. |\n",
            "| **Friday** | **Greek Yogurt Parfait:** 1 cup of plain, low-fat Greek yogurt layered with 1/4 cup of mixed berries (like blueberries) and 1 tbsp of sunflower seeds. | **Mixed Vegetable Khichdi:** A one-pot meal made with brown rice and mixed lentils (dal), cooked with plenty of vegetables like carrots, peas, and beans. Serve with a bowl of yogurt. | **Stuffed Bell Peppers:** 2 medium bell peppers stuffed with a mixture of crumbled paneer/tofu, finely chopped vegetables, and spices, then baked until tender. |\n",
            "| **Saturday**| **Smoothie:** A smoothie made with 1/2 cup silken tofu (for protein), 1/2 cup spinach, 1/4 cup berries, 1 tbsp flax seeds, and unsweetened almond milk. | **Black Bean Salad:** 1 large bowl of boiled black beans mixed with corn, chopped onions, tomatoes, and cilantro. Squeeze fresh lime juice on top. | **Eggplant Curry (Baingan Bharta style):** Roasted and mashed eggplant cooked with onions, tomatoes, and spices. Serve with 1 small whole-wheat roti. |\n",
            "| **Sunday** | **Besan Chilla (Chickpea Flour Pancake):** 2 small pancakes made from chickpea flour batter with added dill, cilantro, and finely chopped onions. Serve with a side of mint-yogurt chutney. | **Vegetable Korma (Healthy Version):** 1 bowl of mixed vegetables (carrots, beans, peas) cooked in a light, nut-based gravy (using almond or cashew paste sparingly) instead of cream. Serve with 1 cup of brown rice. | **Large Mixed Green Salad with Legumes:** A fulfilling salad with lettuce, spinach, arugula, cucumber, topped with 1 cup of mixed boiled legumes (chickpeas, kidney beans) and a light vinaigrette. |\n",
            "\n",
            "---\n",
            "\n",
            "### **Healthy Snack Options (Choose one or two per day, if needed)**\n",
            "\n",
            "*   A small apple with 1 tablespoon of unsalted peanut or almond butter.\n",
            "*   A handful of almonds or walnuts (approx. 15-20).\n",
            "*   Vegetable sticks (cucumber, carrots, bell peppers) with 2 tablespoons of hummus.\n",
            "*   A small bowl of plain low-fat Greek yogurt.\n",
            "*   A glass of buttermilk (unsalted).\n",
            "*   A handful of roasted, unsalted chickpeas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ZERO SHOT Prompting"
      ],
      "metadata": {
        "id": "mlEzywNgcecc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. these are the basics prompting techniques which completly rely on the\n",
        "capability of LLMs.\n",
        "2. no examples are provided in zero shot prompting.\n",
        "3. Direct instruction are given to the model to perform the task.\n",
        "4. LLM are trained on large valume of data and the outputs of LLM's are based on the training that models have undergone.\n"
      ],
      "metadata": {
        "id": "DPUMx6EqcoxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero_short = '''please explain principal component analysis which is part of unsupervised learning.\n",
        "'''\n",
        "output = model.generate_content(zero_short).text\n",
        "print(f'the prompt output is : {output}')\n"
      ],
      "metadata": {
        "id": "x6bP1JldbXsi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36fbd215-2c8f-4954-8b02-36d88c9f08b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the prompt output is : Of course! Let's break down Principal Component Analysis (PCA) in a clear, structured way.\n",
            "\n",
            "### The Elevator Pitch: What is PCA?\n",
            "\n",
            "Imagine you have a spreadsheet with 100 columns describing your customers (age, income, last purchase amount, time on site, etc.). Trying to understand the relationships between all 100 columns is nearly impossible.\n",
            "\n",
            "**Principal Component Analysis (PCA)** is a technique that takes this complex, high-dimensional data and simplifies it by creating a few *new*, artificial features called **Principal Components**. These new components are smart combinations of the old ones and are designed to capture the most important information (the most \"variance\") in the data.\n",
            "\n",
            "Essentially, it's a method for **dimensionality reduction**: reducing the number of features while losing the least amount of information possible.\n",
            "\n",
            "---\n",
            "\n",
            "### The Core Intuition: The Shadow Analogy\n",
            "\n",
            "This is the best way to get an intuitive feel for PCA.\n",
            "\n",
            "Imagine a 3D object, like a person standing in a room. This person is your \"high-dimensional data\" (3 dimensions: height, width, depth). Now, you shine a flashlight on them, and it casts a 2D shadow on the wall. This shadow is your \"low-dimensional representation.\"\n",
            "\n",
            "*   If you shine the light from directly above, the shadow might just be the shape of their head and shoulders. You've lost a lot of information about their pose.\n",
            "*   If you shine the light from the front, you get a classic silhouette. This shadow is much more informative—you can see their shape, posture, and what they're doing.\n",
            "\n",
            "**PCA is the mathematical process of finding the perfect angle to shine the light.**\n",
            "\n",
            "*   The **First Principal Component (PC1)** is the direction (the \"angle\") that creates the shadow with the most possible spread and detail (the most **variance**). It captures the single most important pattern in the data.\n",
            "*   The **Second Principal Component (PC2)** is the next-best angle, but with a rule: it *must* be at a 90-degree angle (orthogonal) to the first one. It captures the most variance that PC1 *didn't* already capture.\n",
            "*   And so on for PC3, PC4, etc., with each new component being orthogonal to all the previous ones.\n",
            "\n",
            "By keeping just the first few shadows (PC1 and PC2), you can often get a very good 2D picture of your original 3D object, making it much easier to analyze.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "---\n",
            "\n",
            "### How PCA Works: A Step-by-Step Guide\n",
            "\n",
            "Let's translate the analogy into a more formal process.\n",
            "\n",
            "#### Step 1: Standardize the Data\n",
            "This is a crucial first step. PCA is sensitive to the scale of your features. If you have one feature in dollars (e.g., `income` from $30,000 to $200,000) and another in years (e.g., `age` from 20 to 70), the `income` feature will dominate the analysis simply because its numbers are bigger.\n",
            "\n",
            "Standardization rescales all features so they have a mean of 0 and a standard deviation of 1, putting them all on a level playing field.\n",
            "\n",
            "#### Step 2: Calculate the Covariance Matrix\n",
            "PCA needs to understand how the different features relate to each other.\n",
            "*   **Variance** measures the spread of a single feature.\n",
            "*   **Covariance** measures how two features move together. A high positive covariance means when one feature goes up, the other tends to go up too.\n",
            "\n",
            "The covariance matrix is a table that shows the covariance between every possible pair of your original features. It summarizes the relationships within the data.\n",
            "\n",
            "#### Step 3: Find the Principal Components (Eigenvectors & Eigenvalues)\n",
            "This is the mathematical core. By performing a calculation (specifically, eigendecomposition) on the covariance matrix, we get two things:\n",
            "\n",
            "*   **Eigenvectors:** These are the directions of the new axes—our \"Principal Components.\" The eigenvector for PC1 points in the direction of maximum variance. The eigenvector for PC2 points in the next-best direction, and so on. They tell you the *direction* of the new features.\n",
            "*   **Eigenvalues:** Each eigenvector has a corresponding eigenvalue. This is a number that tells you *how much variance* is captured by that eigenvector. A big eigenvalue means that principal component is very important.\n",
            "\n",
            "#### Step 4: Sort and Select Components\n",
            "You rank the eigenvectors in order of their eigenvalues, from highest to lowest. The eigenvector with the highest eigenvalue is your **First Principal Component (PC1)**.\n",
            "\n",
            "Now you make a choice. You can calculate an \"explained variance ratio\" for each component. For example, you might find that:\n",
            "*   PC1 explains 75% of the total variance.\n",
            "*   PC2 explains 15% of the total variance.\n",
            "*   PC3 explains 4% of the total variance.\n",
            "*   ...and so on.\n",
            "\n",
            "Together, PC1 and PC2 explain 90% of the information. You might decide that's good enough and discard all the other components. This is the **reduction** step.\n",
            "\n",
            "#### Step 5: Transform the Data\n",
            "The final step is to take your original standardized data and project it onto the new axes (the principal components) you decided to keep. This gives you a new, smaller dataset where the columns are no longer \"age\" and \"income,\" but \"PC1\" and \"PC2\".\n",
            "\n",
            "---\n",
            "\n",
            "### Why is PCA part of Unsupervised Learning?\n",
            "\n",
            "This is a key distinction. **Unsupervised learning** is about finding patterns in data *without any pre-existing labels or target outcomes*. You aren't trying to predict a specific column (like \"will this customer churn?\"). You are just trying to understand the inherent structure of the data itself.\n",
            "\n",
            "PCA is a perfect example of this:\n",
            "*   **It only looks at the input features (X).** It doesn't use or care about a target variable (y).\n",
            "*   Its goal is to describe the data in a simpler way, not to make a prediction. It uncovers the underlying structure (the directions of variance) based solely on the features provided.\n",
            "\n",
            "It's often used as a preprocessing step *before* other learning algorithms (both supervised and unsupervised, like K-Means clustering).\n",
            "\n",
            "### Common Applications\n",
            "\n",
            "1.  **Data Visualization:** Taking data with 10 features and plotting it on a 2D graph using PC1 and PC2 to visually identify clusters or trends.\n",
            "2.  **Noise Reduction:** Minor components often capture noise in the data. By discarding them, you can create a cleaner dataset.\n",
            "3.  **Improving Algorithm Performance:** Many machine learning algorithms slow down or perform poorly when they have too many features (this is called the \"Curse of Dimensionality\"). Running PCA first can make them faster and more effective.\n",
            "4.  **Image Compression:** A high-resolution image has a huge number of features (one for each pixel). PCA can be used to capture the most important features of the image, allowing it to be stored with far less data.\n",
            "\n",
            "### Pros and Cons\n",
            "\n",
            "**Pros:**\n",
            "*   Reduces dimensions and simplifies data.\n",
            "*   Removes redundant features (multicollinearity).\n",
            "*   Can help prevent overfitting in models.\n",
            "*   Speeds up training time for other algorithms.\n",
            "\n",
            "**Cons:**\n",
            "*   **Loss of Interpretability:** Your new features, PC1 and PC2, are mathematical combinations of all the original features. It can be difficult to explain what \"PC1\" means in a business context, whereas \"age\" or \"income\" are easy to understand.\n",
            "*   **Information Loss:** By design, you are throwing some information away. You have to be careful to keep enough components to retain the important parts of the signal.\n",
            "*   **Assumes Linear Relationships:** PCA is based on finding linear correlations. It might not work well if the underlying structure of your data is highly non-linear.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Classification"
      ],
      "metadata": {
        "id": "ZSVZf1KNeEFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero_prompt = '''\n",
        "## you are and expert in classifying the text\n",
        "## you are required to classify the text into positive, negative and neutral.\n",
        "\n",
        "I must say it has exceded my expectations. the build quality is exceptional with a study design that feels premium and durable.\n",
        "the key are well spaced and provid a comfortable typing experience even during prolonged use.\n",
        "\n",
        "## please give reason for classification.\n",
        "## keep it simple and let me know if we can go for the product.\n",
        "## the output should be in bullated format numbered as (eg 1. 2. 3.)\n",
        "'''\n",
        "output = model.generate_content(zero_prompt).text\n",
        "print(f'the prompt output is : {output}')"
      ],
      "metadata": {
        "id": "iDJsx3lCdz61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "65500719-f6eb-40f4-dfad-46c2ff3dcdc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the prompt output is : Of course, here is the classification:\n",
            "\n",
            "1.  **Classification:** Positive\n",
            "\n",
            "2.  **Reason for Classification:** The text uses highly positive and enthusiastic language to describe the product. Words and phrases like \"exceeded my expectations,\" \"exceptional,\" \"premium,\" \"durable,\" and \"comfortable typing experience\" all point to a very satisfying user experience.\n",
            "\n",
            "3.  **Should you go for the product?** Yes. Based on this review, the product is highly recommended as it praises both its build quality and its usability.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "D0JqkfEluMsa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## job evaluation and fitness of job"
      ],
      "metadata": {
        "id": "qBQFGBsVkiVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_desc = '''\n",
        "• Strong understanding of ML fundamentals, Transformers, embeddings, and LLM architecture\n",
        "• Hands-on experience with HuggingFace, PyTorch, TensorFlow, LangChain, or similar tools\n",
        "• Experience working on academic/side projects involving model training or fine-tuning\n",
        "• Ability to experiment, test, validate, and iterate on model behavior\n",
        "• Passion for applied AI and improving real-world model performance\n",
        "'''\n",
        "print(job_desc)"
      ],
      "metadata": {
        "id": "uFF-9gtpkJym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8b8538e-eaff-4b42-a25b-d08d368454b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "• Strong understanding of ML fundamentals, Transformers, embeddings, and LLM architecture\n",
            "• Hands-on experience with HuggingFace, PyTorch, TensorFlow, LangChain, or similar tools\n",
            "• Experience working on academic/side projects involving model training or fine-tuning\n",
            "• Ability to experiment, test, validate, and iterate on model behavior\n",
            "• Passion for applied AI and improving real-world model performance\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pypdf"
      ],
      "metadata": {
        "id": "4bgmjrg7mwG7"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pypdf import PdfReader\n",
        "resume = PdfReader('/content/Anand_AI.pdf')\n",
        "resume.text = ''\n",
        "for page in resume.pages:\n",
        "  resume.text += page.extract_text()\n",
        "\n",
        "prompt = f'compare the \\n\\n{job_desc} with \\n\\n{resume.text} and suggest if i am a good fit? and give me the ATS score after camparing with jd'\n",
        "response = model.generate_content(prompt)\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k8dOCsV_97Oz",
        "outputId": "1221ef4d-3451-479b-b536-4ac8f249f021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Of course. Here is a detailed comparison of the job requirements against Anand Mehto's resume, an analysis of his fit for the role, a simulated ATS score, and actionable recommendations.\n",
            "\n",
            "### Overall Assessment: Is it a Good Fit?\n",
            "\n",
            "**You are a promising fit, especially for a junior or entry-level Generative AI/ML Engineer role.**\n",
            "\n",
            "Your resume shows a strong, proactive effort to pivot into the AI/ML space. You have hands-on project experience with the exact modern tools (LangChain, HuggingFace) that are in high demand. Your Kaggle achievements are a significant differentiator, proving your passion and ability to compete on real-world problems.\n",
            "\n",
            "The main challenge is that your professional experience is not in a direct ML role. You will need to effectively frame your journey as a dedicated and skilled career-changer.\n",
            "\n",
            "---\n",
            "\n",
            "### Detailed Side-by-Side Comparison\n",
            "\n",
            "| Requirement from Job Description | Evidence from Your Resume | Analysis & Fit |\n",
            "| :--- | :--- | :--- |\n",
            "| **1. Strong understanding of ML fundamentals, Transformers, embeddings, and LLM architecture** | **Skills:** Lists \"Supervised & Unsupervised Learning,\" \"Transformers,\" \"Generative AI,\" \"RAG.\" <br> **Projects:** The \"Generative AI Resume Enhancement System\" uses GPT models, implying familiarity with LLM application. The \"Suicide-Risk-Detection\" project uses NLP. | **Good Match.** You list the core concepts like Transformers and ML fundamentals. Your project on RAG demonstrates a practical understanding of a key LLM architecture. The resume could be strengthened by explicitly mentioning \"LLM architecture\" and \"embeddings\" if you have experience with them (e.g., word2vec, sentence transformers). |\n",
            "| **2. Hands-on experience with HuggingFace, PyTorch, TensorFlow, LangChain, or similar tools** | **Skills:** Explicitly lists **HuggingFace**, **TensorFlow**, and **LangChain**. <br> **Projects:** The Resume Enhancement project directly mentions using **LangChain** and **GPT models**. | **Excellent Match.** This is one of your strongest areas. You have direct, project-based experience with the most relevant and modern tools listed in the job description. |\n",
            "| **3. Experience working on academic/side projects involving model training or fine-tuning** | **Projects:** <br> • Suicide-Risk-Detection: \"Built an NLP model to detect suicide risk.\" <br> • Diabetes-Prediction (ANN): \"Developed an ANN-based diabetes prediction model... with hyperparameter tuning.\" | **Strong Match.** You have multiple end-to-end projects that clearly involved building and training models. While \"fine-tuning\" is not explicitly mentioned, \"hyperparameter tuning\" is very closely related and demonstrates the required skill set. |\n",
            "| **4. Ability to experiment, test, validate, and iterate on model behavior** | **Projects:** The Diabetes project mentions, \"Evaluated results using ROC-AUC, confusion matrix, and classification metrics.\" <br> **Achievements:** Competing on Kaggle inherently requires constant iteration, testing, and validation to improve a model's score. | **Excellent Match.** You provide concrete evidence of using standard evaluation metrics. Your Kaggle performance is a powerful, implicit proof of your ability to iterate and improve model performance under competitive pressure. |\n",
            "| **5. Passion for applied AI and improving real-world model performance** | **Summary:** \"delivering actionable business insights through end-to-end machine learning projects.\" <br> **Achievements:** \"Participated in MachineHack and Kaggle competitions, achieving multiple top-5 leaderboard positions on real-world ML challenges.\" | **Excellent Match.** This is your biggest selling point. The Kaggle achievements are the best possible way to demonstrate passion and a drive to solve real problems. It shows you go beyond coursework and are intrinsically motivated. |\n",
            "\n",
            "---\n",
            "\n",
            "### Simulated ATS (Applicant Tracking System) Score\n",
            "\n",
            "An ATS scans your resume for keywords from the job description. Based on a direct comparison, here is your likely score.\n",
            "\n",
            "**ATS Score: 78/100**\n",
            "\n",
            "#### Breakdown:\n",
            "\n",
            "*   **Keyword Match (High):** Your resume hits most of the critical technical keywords:\n",
            "    *   **Found:** `Machine Learning`, `Transformers`, `HuggingFace`, `TensorFlow`, `LangChain`, `NLP`, `Model Training` (implied via projects), `Validate` (implied via evaluation metrics).\n",
            "    *   **Missing/Weak:** `PyTorch`, `Embeddings`, `Fine-tuning`, `LLM architecture` (the specific term is missing, though the concept is present).\n",
            "*   **Experience Match (Medium):** The ATS will flag that your professional titles (`Technical Recruitment Specialist`, `Quality Control Inspector`) do not align with an ML role. This is where a human reviewer becomes essential.\n",
            "*   **Project Relevance (High):** The keywords within your project descriptions are highly relevant and will score very well, especially the Generative AI project.\n",
            "\n",
            "This is a good score that will almost certainly pass an initial ATS screen and get your resume in front of a human recruiter.\n",
            "\n",
            "---\n",
            "\n",
            "### Recommendations for Improvement\n",
            "\n",
            "You have a very strong foundation. These small changes can make your resume even more compelling.\n",
            "\n",
            "1.  **Explicitly Add Missing Keywords:**\n",
            "    *   If you used word embeddings in your NLP project, add the term \"**embeddings**\" (e.g., \"Utilized TF-IDF and word embeddings to represent text features\").\n",
            "    *   If any of your projects involved taking a pre-trained model and adapting it to your data, rephrase it to use the term \"**fine-tuning**.\" For example: \"Fine-tuned a BERT-based model for suicide risk classification.\"\n",
            "    *   In your skills section under \"Generative AI,\" add \"**LLM Architecture (e.g., Transformer-based)**\" to hit that keyword directly.\n",
            "\n",
            "2.  **Strengthen Your Summary:**\n",
            "    *   Your current summary is good but can be tailored. Lead with your most relevant skills.\n",
            "    *   **New Version Idea:** \"Proactive and results-driven professional transitioning into Generative AI, with a proven track record of achieving top-5 Kaggle rankings. Hands-on experience developing end-to-end ML solutions using **LangChain, HuggingFace, and TensorFlow**. Passionate about applying **Transformer models** and **RAG** architectures to solve real-world business problems.\"\n",
            "\n",
            "3.  **Bridge Your Professional Experience:**\n",
            "    *   Connect your past roles to data skills, even if they weren't ML-focused.\n",
            "    *   **For the Recruitment role:** Instead of \"Managed candidate data,\" try \"**Analyzed** candidate pipeline data using ATS tools to identify bottlenecks and improve screening efficiency by X%.\" This reframes it as an analytical role.\n",
            "    *   **For the Quality Control role:** You already do this well by mentioning a 15% reduction in rework. This is excellent—keep it.\n",
            "\n",
            "By making these adjustments, you can increase your ATS score and present a more polished and targeted narrative to recruiters, solidifying your position as a strong candidate for this type of role.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Few short  prompting"
      ],
      "metadata": {
        "id": "k8Ud6MDZgBop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "few_short = '''\n",
        "provide a solution to the mathematical problem\n",
        "stated below. Give the final output only\n",
        "Q: 4X + 8 = 0 then X is\n",
        "A: -2\n",
        "\n",
        "Q: 5X + 2Y = 8 when X=0 is Y = 4\n",
        "A: 4\n",
        "Q: 5X + 2Y = 8 when X=2 is Y is\n",
        "A: 3\n",
        "Q: 3X*2 + Y = 0 when X= 4 then Y is\n",
        "A:\n",
        "'''\n",
        "output = model.generate_content(few_short).text\n",
        "print(f'the prompt output is :{output}')"
      ],
      "metadata": {
        "id": "JdmNjRUeqdj0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0e7151a-328f-4a9a-f014-4e4ebff386d0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the prompt output is :-24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot = '''\n",
        "find the data when the module should have been conducted\n",
        "\n",
        "example 1:\n",
        "input: python for data science course was to start on 12th oct 2024. this takes 5 days to complete. it got delayed by 10 days.\n",
        "conclusion: so the python for data science course started actually on 22nd oct 2024\n",
        "\n",
        "example2:\n",
        "input: the next course that was to start was eda. it was a start on 10th nov 2024. it is a 5 day course. the faculy\n",
        "was readily available and hence the course was preponed by 5 days.\n",
        "conclusion: so the eda course started actually on 5th nov 2024.\n",
        "\n",
        "example3:\n",
        "input: statistics course was to start on 17th nov 2024. statistics is 5 day course. it was decided to preponse this course by 3 days.\n",
        "conclusion: so the statistics course started actually on 20th nov 2024.\n",
        "'''\n",
        "output = model.generate_content(few_shot).text\n",
        "print(f'the prompt output is :{output}')"
      ],
      "metadata": {
        "id": "dMtBXJzzGXHx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d7fa6105-1f79-4ca3-d524-d5f74ff04726"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the prompt output is :input: mlops was the next course. it was to start on 22nd dec 2024 and it is a 10 day course. this was delayed by 12 days.\n",
            "conclusion: so the mlops course started actually on 3rd jan 2025.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [ {\n",
        "    'input': 'i am learning generative  AI',\n",
        "    'output': 'estoy apprendiendo AI generative'\n",
        "    }, {\n",
        "    'input': 'life is good after learning AI',\n",
        "    'output': 'livet er godt effer at have laert AI'\n",
        "}]\n",
        "prompt = 'tranaslate the following into hindi. i hate to go to study these days'\n",
        "response = model.generate_content(prompt+'\\n\\n{examples}\\n\\n'+str(examples))\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "arXZCAIxGqIt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5cb8238-7f60-41e1-ea35-8cea72737736"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "आजकल मेरा पढ़ाई करने का मन नहीं करता। (Aajkal mera padhai karne ka man nahi karta.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chain of Thoughts"
      ],
      "metadata": {
        "id": "EQYajpIyierx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. in chain of thoughts, we give LLM a step by step process to describe the reasoning logic.\n",
        "2. so we create logical chain of reasoning to arrive at the solution or the response.\n",
        "3. step by step process inducing the thought into the LLMs which refines the explanation provided by the LLMs.\n",
        "4. It brings in improved clarity and even the complex problem can be well explained in simpler way.\n",
        "5. the accuracy tends to increasse by structuring the thought process\n",
        "6. step by step process also ensures that the logical sequences are followed."
      ],
      "metadata": {
        "id": "n4ByqFgvilCO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# the ambiguity of life career"
      ],
      "metadata": {
        "id": "xOYFFvSpjvXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# epic problem: Pursue masters from USA or continue with the job in India\n",
        "thought = 'Question-Act As a career expert in the field of AI and answer the following question. Do i continue my job in india that  paying me descent money or shall i go to USA to pursue my masters from IVy league colleges such MIT and standford etc.'\n",
        "\n",
        "'''\n",
        "evaluate the options:\n",
        "1. asses the current situation: i have recently gotten into job as data scientist and quite content my role. I am doing \\\n",
        "something serious to uplift my carrer. howeever, the seniour in my company have gone abroad to pursue higher studies.\\\n",
        "this gets me into the thought of pursuing higher studies.\n",
        "\n",
        "2. if i leave the job : if i have to leave the job then i have to leave my family behind and at the same time there is an \\\n",
        "opportunity cost involved. what that also means is, if i am out of job, i will loose on the salary that i was getting.\\\n",
        "this is one of the issues that is not let me decide.\n",
        "\n",
        "3. financial situation: i understand pursuing master from abroad is very costly and can cost me heavily. it might\\\n",
        "take couple of years to come out my education loan. howeever, i feel it is worth doing it once in life time opportunity\\\n",
        "moreever i do not have financial constrains.\n",
        "\n",
        "now i want you to guide me using logical reasoning and suggest me the correct options providing weightage to all the options\\\n",
        "that you suggest.\n",
        "\n",
        "Note: the optiones that you provide shoud be practical and can be enacted.\n",
        "'''\n",
        "response = model.generate_content(thought)\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "id": "ihfAHWFIjftz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cb2d72b6-c8f1-462e-ceb8-b82f3f36a677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Excellent question. This is a classic and significant crossroads for many talented tech professionals in India. As a career expert in AI, I won't give you a simple \"yes\" or \"no.\" Instead, I'll provide a framework to help you make the best decision for *your* specific goals and circumstances.\n",
            "\n",
            "Let's break this down into a structured analysis.\n",
            "\n",
            "### The Core of Your Decision\n",
            "\n",
            "This isn't just about a job vs. a degree. It's a decision between two fundamentally different career trajectories:\n",
            "\n",
            "1.  **The India Path:** Linear, stable, and potentially rapid growth within a booming, but still maturing, ecosystem. You become a leader in a major market.\n",
            "2.  **The US Path (MIT/Stanford):** A high-risk, high-reward \"reset\" that catapults you into the global epicenter of AI innovation, offering a potentially exponential, non-linear career trajectory.\n",
            "\n",
            "Let's analyze the pros and cons of each.\n",
            "\n",
            "---\n",
            "\n",
            "### Path 1: Continue Your Job in India\n",
            "\n",
            "This is the path of **compounding momentum**. You are already established, earning, and growing.\n",
            "\n",
            "**Pros:**\n",
            "\n",
            "*   **Financial Security & No Debt:** This is the most significant advantage. A Master's in the US will cost you upwards of $100,000-$150,000 (tuition + living). Staying means you continue to earn, save, and invest, while your US-bound peers are accumulating massive debt.\n",
            "*   **Career Momentum:** You can continue to climb the ladder, gun for promotions, and take on leadership roles. Leaving means you hit the \"pause\" button on your professional experience for two years.\n",
            "*   **The Booming Indian AI Ecosystem:** India's AI scene is exploding. You have the opportunity to become a senior figure or a leader in this high-growth market relatively quickly. Companies from GCCs (Global Capability Centers) to high-growth startups are all desperate for experienced AI talent.\n",
            "*   **Lower Cost of Living & Support System:** Your \"decent money\" goes much further in India. You also have the invaluable benefit of your existing social and family support network.\n",
            "\n",
            "**When This Path is Right for You:**\n",
            "\n",
            "*   If your primary goal is financial stability and a clear, predictable path to a senior leadership role *within India*.\n",
            "*   If you have significant family or personal commitments that make a move abroad difficult.\n",
            "*   If you are highly risk-averse.\n",
            "*   If your current role offers you opportunities to work on cutting-edge AI problems (this is a key differentiator).\n",
            "\n",
            "---\n",
            "\n",
            "### Path 2: Pursue a Master's in the USA (from a top-tier university)\n",
            "\n",
            "This is the path of **long-term investment and global ambition**. The names you mentioned—MIT, Stanford, CMU, Berkeley—are not just colleges; they are global brands that act as launchpads.\n",
            "\n",
            "**Pros:**\n",
            "\n",
            "*   **Unparalleled Brand & Network:** The single biggest advantage. The degree itself is secondary to the network you build. Your classmates will be future founders of unicorns, lead researchers at Google Brain, and VCs. This network is a lifelong asset that is nearly impossible to build otherwise.\n",
            "*   **Cutting-Edge Research and Knowledge:** You will be learning from and working with the professors who are *defining* the future of AI. You get access to labs, resources, and a level of academic rigor that is unmatched. You move from being an *implementer* of AI to an *innovator*.\n",
            "*   **Exponentially Higher Earning Potential (Long-Term):** A new graduate from a top AI Master's program can expect a starting total compensation (salary + stock + bonus) of $200,000 - $300,000+ in the US. This figure can dwarf what you would earn in India even after several more years of experience. The wealth-building potential through stock options (RSUs) at major tech firms or successful startups is life-changing.\n",
            "*   **Global Opportunities:** This degree is a golden ticket not just for the US, but for top AI roles anywhere in the world (London, Zurich, Singapore, etc.).\n",
            "*   **The Silicon Valley Mindset:** Being immersed in that environment fundamentally changes how you think about problems, risk, and scale. It's an intangible but incredibly valuable benefit, especially if you have entrepreneurial ambitions.\n",
            "\n",
            "**Cons & Risks (Do NOT ignore these):**\n",
            "\n",
            "*   **Extreme Financial Risk:** You will likely take on significant student debt.\n",
            "*   **Immigration Uncertainty:** The H-1B visa is a lottery system. There is a real chance that you may not be able to stay and work in the US long-term after your degree, despite your qualifications.\n",
            "*   **Opportunity Cost:** You lose two years of salary and work experience.\n",
            "*   **Extreme Competition:** Getting into these programs is incredibly difficult. It requires a stellar academic record, great test scores (GRE), compelling research or project work, and outstanding letters of recommendation.\n",
            "\n",
            "---\n",
            "\n",
            "### A Structured Framework for Your Decision\n",
            "\n",
            "Ask yourself these critical questions. Be brutally honest.\n",
            "\n",
            "1.  **What is my ultimate career ambition?**\n",
            "    *   **\"I want to be a CTO/Head of AI at a major company in India.\"** -> Staying in India is a very strong and direct path.\n",
            "    *   **\"I want to be a Research Scientist at DeepMind or OpenAI.\"** -> The US Master's is almost non-negotiable.\n",
            "    *   **\"I want to build my own AI startup with global impact.\"** -> The US Master's provides the network, knowledge, and access to capital that makes this far more likely.\n",
            "\n",
            "2.  **What is my financial risk tolerance?**\n",
            "    *   Can you (and your family) stomach the idea of being $120,000 in debt, with the risk of having to return to India to pay it off on an Indian salary? If this thought gives you nightmares, lean towards staying.\n",
            "\n",
            "3.  **How strong is my academic and professional profile?**\n",
            "    *   Do you have a high GPA from a top Indian university (IIT, BITS, NIT)? Have you published research papers? Do you have unique, high-impact projects on your resume? Be realistic about your chances of admission to a top-5 program. Applying is a job in itself.\n",
            "\n",
            "4.  **What does \"decent money\" actually mean to me?**\n",
            "    *   Is it enough to live comfortably, or is it enough to build significant, life-changing wealth? The scale of wealth creation possible in the US tech scene is on a different level. This is a question of personal financial goals.\n",
            "\n",
            "### The Expert's Take & Final Recommendation\n",
            "\n",
            "If you are young (under 30), have a strong academic profile, a high-risk tolerance, and global ambitions, I would strongly advise you to **aim for the US Master's.**\n",
            "\n",
            "**The ROI of a degree from MIT or Stanford in the field of AI is astronomical.** The two years of lost income and the student debt are a rounding error when compared to the potential long-term career and financial trajectory it unlocks. The network and the brand on your resume will open doors for the rest of your life that would otherwise remain closed.\n",
            "\n",
            "**Actionable Plan:**\n",
            "\n",
            "1.  **Don't Quit Your Job Yet.** De-risk the decision.\n",
            "2.  **Test the Waters:** Start preparing for the GRE and TOEFL *now*. See what scores you get. A great score makes the decision easier.\n",
            "3.  **Build Your Profile:** While working, focus on projects that are research-oriented. Try to publish a paper or contribute to a significant open-source AI project.\n",
            "4.  **Reach Out:** Use LinkedIn to connect with alumni from your target schools. Ask them about their experience and the ROI they've seen.\n",
            "5.  **Apply:** Put together the absolute best application you can. Apply to a mix of dream schools (MIT, Stanford) and ambitious but more attainable schools (e.g., Georgia Tech, UT Austin, UCSD).\n",
            "\n",
            "If you get into a **Top 5-10 CS/AI program**, the decision is almost made for you. Take the leap.\n",
            "\n",
            "If you don't get into a top-tier program, or if you realize during the process that you cannot tolerate the financial and immigration risks, then you can double down on your career in India with no regrets, knowing you fully explored the alternative. In that scenario, you'll be a highly valued asset in the Indian market with several years of solid experience under your belt.\n",
            "\n",
            "This way, you make an informed decision, not a speculative one. Good luck.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "thought = '''\n",
        "you are an expert in virtual tour for the past 72 years in india. you have people coming from all parts of the world in delhibegin your itinary  step by step.\n",
        "\n",
        "1. give all the important location in and arund Delhi.\n",
        "2. give the reason why these monuments where built and who had built these.\n",
        "3. How long did it take to construct these monuments.\n",
        "4. when did it start and when did it end.\n",
        "5. also mentioin the number of people who visit these monuments through the year.\n",
        "\n",
        "can you also make it appear romantic and joyful so that the reader gets interest to read this itinary.\n",
        "\n",
        "'''\n",
        "response = model.generate_content(thought)\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "EfH4XmSJq4hA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf00ec85-8af1-4313-8b79-29821b6f96bf"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namaste, my dear travelers from across the seven seas!\n",
            "\n",
            "Welcome to my city, my Delhi. For 72 glorious years, I have walked these very streets, from the cool marble floors of Mughal palaces to the bustling, spice-scented lanes of the old city. I have seen empires fall and a new nation rise, all from the heart of this incredible place. Delhi is not just a city; she is a grand old dame who wears her history like glittering jewels. She is a symphony of sights, sounds, and stories, and I am here to be your maestro.\n",
            "\n",
            "So, take my hand, and let us embark on a journey not just through stone and mortar, but through tales of love, ambition, and timeless beauty. This is not just an itinerary; it is an invitation to fall in love.\n",
            "\n",
            "---\n",
            "\n",
            "### **Day 1: The Imperial Heartbeat of Emperors and Queens**\n",
            "\n",
            "Our first day is a dance with the grandeur of the Mughal Empire, an era of unparalleled romance and architectural poetry.\n",
            "\n",
            "#### **1. Humayun's Tomb: A Love Letter in Stone**\n",
            "\n",
            "Our journey begins not with a king's fortress, but with a queen's heart. As we step through the grand gateway, the world outside melts away. Before you lies a vision of perfect symmetry, a magnificent tomb floating amidst lush green gardens, where fountains whisper secrets of the past. This is not a place of sorrow; it is a celebration of eternal love.\n",
            "\n",
            "*   **Why was it built?** This masterpiece was commissioned by Empress Bega Begum, the grieving widow of the second Mughal Emperor, Humayun. It is said her love for him was so profound that she dedicated her life to creating a paradise on Earth for his final resting place. It was the first garden-tomb on the Indian subcontinent and became the inspiration for the Taj Mahal itself!\n",
            "*   **Who built it?** Empress Bega Begum, with the genius of Persian architects Mirak Mirza Ghiyas and his son, Sayyid Muhammad.\n",
            "*   **How long did it take?** A labor of love that spanned nearly a decade.\n",
            "*   **Construction Period:** The first stone was laid in 1565, and this monument to love was unveiled in all its glory in 1572.\n",
            "*   **Annual Visitors:** Each year, over **2 million souls** come to wander its serene pathways, drawn by the silent, powerful story of a love that defied even death.\n",
            "\n",
            "#### **2. The Red Fort (Lal Qila): The Crimson Heart of an Empire**\n",
            "\n",
            "Now, let us journey to the very soul of Mughal power. As we approach, you will see a fortress of sandstone so deep red it seems to blush at sunrise and sunset. This is the Red Fort, a city within a city, from where the mighty Mughal emperors ruled over a vast subcontinent. Imagine the sound of royal elephants, the rustle of silk curtains, and the declaration of emperors from its ramparts.\n",
            "\n",
            "*   **Why was it built?** When the great Emperor Shah Jahan decided to shift his capital from Agra to Delhi, he envisioned a new city, Shahjahanabad. The Red Fort was to be the magnificent palace-fortress at its heart, a symbol of his unparalleled power and artistic taste.\n",
            "*   **Who built it?** The visionary emperor of the Taj Mahal, **Shah Jahan**.\n",
            "*   **How long did it take?** An astonishing feat of engineering and art, it took approximately **9 years** to complete.\n",
            "*   **Construction Period:** The foundations were laid in 1639, and the emperor moved in in 1648.\n",
            "*   **Annual Visitors:** A beacon of India's freedom (the Prime Minister hoists the national flag here every Independence Day), it welcomes nearly **4 million visitors** a year, who come to hear the echoes of history.\n",
            "\n",
            "---\n",
            "\n",
            "### **Day 2: Echoes of Ancient Victories and Modern Sacrifice**\n",
            "\n",
            "Today, we travel further back in time, and then leap forward to honor the heroes of a new era. It's a day of contrasts, of towering ambition and profound remembrance.\n",
            "\n",
            "#### **3. Qutub Minar: A Towering Song of Victory**\n",
            "\n",
            "Look up! Gaze upon this magnificent, fluted sandstone tower that seems to pierce the very heavens. The Qutub Minar is not just a tower; it's a story of conquest, faith, and the beginning of a new dynasty in India. Each of its five storeys tells a different tale, with intricate carvings and verses from the Quran. To stand at its base is to feel small, yet connected to a history that is centuries old.\n",
            "\n",
            "*   **Why was it built?** It was built to commemorate the victory of Qutb-ud-din Aibak over the last Hindu kingdom of Delhi. It served as a minaret for the adjoining mosque, from where the call to prayer would ring out across the new capital.\n",
            "*   **Who built it?** Construction was started by **Qutb-ud-din Aibak**, the founder of the Delhi Sultanate, and completed by his successors, notably Iltutmish.\n",
            "*   **How long did it take?** This was a generational project, taking nearly **150 years** through various stages of construction and additions by different rulers.\n",
            "*   **Construction Period:** It was started around **1193** and its final storey was completed in the 14th century.\n",
            "*   **Annual Visitors:** This UNESCO World Heritage site is a magnet for history lovers, drawing over **3 million admirers** annually.\n",
            "\n",
            "#### **4. India Gate: An Eternal Flame of Love and Loss**\n",
            "\n",
            "As the sun begins to set, we arrive at a place of solemn beauty and immense pride. India Gate stands as a silent, stoic sentinel in the heart of the city. It is an arch of triumph, but also a memorial of profound sacrifice. In the evening, as the monument is bathed in light and families gather on the surrounding lawns, it transforms into a place of joyful life, a beautiful tribute to the men who gave their today for our tomorrow.\n",
            "\n",
            "*   **Why was it built?** It was built to honor the 84,000 soldiers of the British Indian Army who lost their lives during the First World War and the Third Anglo-Afghan War. Their names are etched forever onto its walls.\n",
            "*   **Who built it?** It was designed by the famous British architect **Sir Edwin Lutyens**.\n",
            "*   **How long did it take?** It took a decade of dedicated work.\n",
            "*   **Construction Period:** The foundation was laid in **1921**, and it was inaugurated in **1931**.\n",
            "*   **Annual Visitors:** As a public space and a national monument, it is visited by **tens of millions** of people every year, making it one of the most visited and beloved landmarks in all of India.\n",
            "\n",
            "---\n",
            "\n",
            "### **Day 3: A Sojourn of Spiritual Serenity and Artistic Splendor**\n",
            "\n",
            "Our final day together is a balm for the soul, showcasing the harmony and artistic brilliance that define modern Delhi.\n",
            "\n",
            "#### **5. Lotus Temple: A Prayer in Marble**\n",
            "\n",
            "Prepare to be mesmerized. Rising from a series of nine shimmering pools is a structure that looks like a lotus flower about to bloom. This is the Baháʼí House of Worship, a modern marvel of peace. There are no idols or priests inside, only a vast, silent hall where people of all faiths are welcome to sit and meditate. The silence here is the most beautiful sound you will hear in Delhi.\n",
            "\n",
            "*   **Why was it built?** As a Baháʼí House of Worship, it was built to be a space for all of humanity to come together as one, regardless of religion, to worship God.\n",
            "*   **Who built it?** Designed by Iranian architect **Fariborz Sahba**, and commissioned by the Baháʼí community.\n",
            "*   **How long did it take?** The intricate design required incredible precision and took about **6 years** to construct.\n",
            "*   **Construction Period:** Work began in **1980** and the temple opened its petals to the public in **1986**.\n",
            "*   **Annual Visitors:** It is one of the most visited buildings in the world, attracting an incredible **4 to 5 million people** every year, a testament to its message of unity and peace.\n",
            "\n",
            "#### **6. Akshardham Temple: A Breathtaking Ode to Culture**\n",
            "\n",
            "Our grand finale is a spectacle of such epic proportions, you will scarcely believe it was built in our lifetime. Akshardham is not just a temple; it is a sprawling campus celebrating 10,000 years of Indian culture, spirituality, and architecture. Every inch is carved with breathtaking detail, from deities and dancers to flora and fauna. Stay for the evening musical fountain show—it is a story of life told through water, light, and sound that will leave you spellbound.\n",
            "\n",
            "*   **Why was it built?** It was built to fulfill the wish of the spiritual head of the BAPS organization, Pramukh Swami Maharaj, as a timeless showcase of Hindu and Indian traditions, spirituality, and art.\n",
            "*   **Who built it?** It was created by thousands of artisans and volunteers of the **BAPS Swaminarayan Sanstha**.\n",
            "*   **How long did it take?** In what can only be described as a modern miracle, this colossal complex was completed in just **5 years**.\n",
            "*   **Construction Period:** An astonishingly swift journey from **2000 to 2005**.\n",
            "*   **Annual Visitors:** It draws an estimated **5 to 6 million visitors** a year, accounting for nearly 70% of all tourists who visit Delhi.\n",
            "\n",
            "---\n",
            "\n",
            "My dear friends, this is but a glimpse into the heart of my beloved Delhi. The real magic lies in the moments in between—the taste of a spicy chaat in Chandni Chowk, the call of a peacock in a quiet garden, the smile of a stranger.\n",
            "\n",
            "Delhi is a story, and she is waiting to share it with you. Your chariot awaits.\n",
            "\n",
            "With the warmest wishes,\n",
            "\n",
            "Your Guide of 72 Years.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Math and Logical Thinking\n",
        "thought = '''\n",
        "You are an expert in the field of mathematics and logical reasoning.\n",
        "we are required to solve a complex problemm which is in power of 2 (quadratic equation)\n",
        "lets take an example and then divide this into step by step process\n",
        "\n",
        "X**2 + 2XY + Y**2 = 0\n",
        "step 1: split them into component of x and y\n",
        "step 2: look for the common factors. think in such a way that you put this in the form of formula like (X+Y)**2\n",
        "step 3: now equate this to = 0 and solve for x and y\n",
        "step 4: provide the values of x and y.\n",
        "solve this complex equation\n",
        "2X**2 + 10XY + 4Y**2 = 0\n",
        "\n",
        "'''\n",
        "response = model.generate_content(thought)\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "EY17igGaWheM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8fa3d655-b21c-4ce5-aa0b-ab9005f6a2a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Excellent question. Your structured, step-by-step approach is the hallmark of a great logical thinker. Let's use your framework to solve this problem.\n",
            "\n",
            "As an expert in mathematics, I commend your method. You've correctly identified that recognizing algebraic identities (like `(X+Y)**2`) is a powerful shortcut. We will follow your process precisely.\n",
            "\n",
            "First, let's quickly apply your steps to your example to confirm the method.\n",
            "\n",
            "### Example: `X**2 + 2XY + Y**2 = 0`\n",
            "\n",
            "*   **Step 1: Split them into components of X and Y.**\n",
            "    The components are `X**2`, `2XY`, and `Y**2`.\n",
            "\n",
            "*   **Step 2: Look for the common factors / put this in the form of a formula.**\n",
            "    We recognize this as the perfect square expansion of `(X+Y)**2`.\n",
            "    So, `X**2 + 2XY + Y**2` is equivalent to `(X+Y)**2`.\n",
            "\n",
            "*   **Step 3: Now equate this to = 0 and solve for X and Y.**\n",
            "    `(X+Y)**2 = 0`\n",
            "    Taking the square root of both sides gives:\n",
            "    `X + Y = 0`\n",
            "\n",
            "*   **Step 4: Provide the values of X and Y.**\n",
            "    From the equation `X + Y = 0`, we find the relationship between X and Y:\n",
            "    `X = -Y`\n",
            "    This means that for any value of Y, X must be its negative for the equation to be true (e.g., if Y=5, X=-5).\n",
            "\n",
            "---\n",
            "\n",
            "### Now, let's solve the complex equation: `2X**2 + 10XY + 4Y**2 = 0`\n",
            "\n",
            "We will follow your steps, but we'll need a more powerful tool in Step 2, as this equation is not a simple perfect square.\n",
            "\n",
            "#### **Preliminary Step: Simplification**\n",
            "\n",
            "Before we begin, a good mathematician always looks to simplify. Notice that all the coefficients (2, 10, and 4) are divisible by 2. Let's divide the entire equation by 2 to make it easier to work with.\n",
            "\n",
            "`(2X**2 + 10XY + 4Y**2) / 2 = 0 / 2`\n",
            "This simplifies to:\n",
            "**`X**2 + 5XY + 2Y**2 = 0`**\n",
            "\n",
            "Now, we will apply your process to this simpler, but equivalent, equation.\n",
            "\n",
            "#### **Step 1: Split them into components of X and Y**\n",
            "\n",
            "We will view this as a quadratic equation in terms of `X`. The standard form of a quadratic equation is `ax**2 + bx + c = 0`.\n",
            "If we map our equation to this form, we get:\n",
            "\n",
            "*   `a = 1`\n",
            "*   `b = 5Y` (The coefficient of the X term)\n",
            "*   `c = 2Y**2` (The term without X)\n",
            "\n",
            "#### **Step 2: Look for a formula to solve this**\n",
            "\n",
            "Your intuition to use a formula is correct. The `(X+Y)**2` formula is for a specific case. For a general quadratic equation like this one, which is not a perfect square, the most powerful tool is the **Quadratic Formula**.\n",
            "\n",
            "The formula is: `X = [-b ± sqrt(b**2 - 4ac)] / 2a`\n",
            "\n",
            "We will use this formula to solve for `X`.\n",
            "\n",
            "#### **Step 3: Equate this to = 0 and solve for X and Y**\n",
            "\n",
            "Now we substitute our components from Step 1 (`a=1`, `b=5Y`, `c=2Y**2`) into the Quadratic Formula.\n",
            "\n",
            "`X = [-(5Y) ± sqrt((5Y)**2 - 4 * 1 * (2Y**2))] / (2 * 1)`\n",
            "\n",
            "Let's solve this step-by-step:\n",
            "\n",
            "1.  Simplify the terms:\n",
            "    `X = [-5Y ± sqrt(25Y**2 - 8Y**2)] / 2`\n",
            "\n",
            "2.  Simplify the expression inside the square root (the discriminant):\n",
            "    `X = [-5Y ± sqrt(17Y**2)] / 2`\n",
            "\n",
            "3.  Take the square root of `17Y**2`. The square root of `Y**2` is `Y`, and the square root of 17 is `sqrt(17)`.\n",
            "    `X = [-5Y ± Y * sqrt(17)] / 2`\n",
            "\n",
            "This gives us two possible solutions for the relationship between X and Y because of the `±` symbol.\n",
            "\n",
            "#### **Step 4: Provide the values of X and Y**\n",
            "\n",
            "The solutions are not single numbers but rather the relationships between `X` and `Y`. We can factor out `Y` from the numerator to make this clear.\n",
            "\n",
            "`X = [Y * (-5 ± sqrt(17))] / 2`\n",
            "\n",
            "This leads to our two distinct solutions:\n",
            "\n",
            "**Solution 1:**\n",
            "`X = ((-5 + sqrt(17)) / 2) * Y`\n",
            "Approximately, `X ≈ ((-5 + 4.123) / 2) * Y`, which is **`X ≈ -0.438 * Y`**\n",
            "\n",
            "**Solution 2:**\n",
            "`X = ((-5 - sqrt(17)) / 2) * Y`\n",
            "Approximately, `X ≈ ((-5 - 4.123) / 2) * Y`, which is **`X ≈ -4.562 * Y`**\n",
            "\n",
            "### Conclusion\n",
            "\n",
            "For the equation `2X**2 + 10XY + 4Y**2 = 0` to be true, the relationship between `X` and `Y` must be one of the two ratios we found. For any value you choose for `Y` (other than 0), you will get two possible values for `X` that satisfy the equation. This is the complete solution to the problem.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tree of thoughts\n"
      ],
      "metadata": {
        "id": "FRG-t_frbGnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain-google-genai\n",
        "!pip install -q langchain"
      ],
      "metadata": {
        "id": "SrzhNSFAiiwV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8593d711-0e7f-4795-c226-bd7578c96743"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/475.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m471.0/475.0 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.0/475.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/343.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.7/343.7 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-google-genai 2.0.10 requires langchain-core<0.4.0,>=0.3.37, but you have langchain-core 1.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-generativeai langchain_google_genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "G83-FP_SF_io",
        "outputId": "b2740516-b133-45a7-8883-350a989b573c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: langchain_google_genai in /usr/local/lib/python3.12/dist-packages (3.2.0)\n",
            "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
            "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.28.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.187.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.43.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.12.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (1.2.0)\n",
            "INFO: pip is looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain_google_genai\n",
            "  Using cached langchain_google_genai-3.2.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_google_genai-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_google_genai-3.0.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_google_genai-3.0.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_google_genai-3.0.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (1.1.0)\n",
            "  Downloading langchain_google_genai-3.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading langchain_google_genai-2.1.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain_google_genai-2.1.11-py3-none-any.whl.metadata (6.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.10-py3-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.9-py3-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.8-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_google_genai-2.1.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_google_genai-2.1.6-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.10-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.37 (from langchain_google_genai)\n",
            "  Downloading langchain_core-0.3.80-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.37->langchain_google_genai) (0.4.47)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.37->langchain_google_genai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.37->langchain_google_genai) (1.33)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.37->langchain_google_genai) (6.0.3)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.4.0,>=0.3.37->langchain_google_genai) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<0.4.0,>=0.3.37->langchain_google_genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain_google_genai) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain_google_genai) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain_google_genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain_google_genai) (0.25.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.11.12)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain_google_genai) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain_google_genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain_google_genai) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain_google_genai) (1.3.1)\n",
            "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.0.10-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.80-py3-none-any.whl (450 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.8/450.8 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-core, google-ai-generativelanguage, langchain_google_genai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.1.0\n",
            "    Uninstalling langchain-core-1.1.0:\n",
            "      Successfully uninstalled langchain-core-1.1.0\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.9.0\n",
            "    Uninstalling google-ai-generativelanguage-0.9.0:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.9.0\n",
            "  Attempting uninstall: langchain_google_genai\n",
            "    Found existing installation: langchain-google-genai 3.2.0\n",
            "    Uninstalling langchain-google-genai-3.2.0:\n",
            "      Successfully uninstalled langchain-google-genai-3.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langgraph-prebuilt 1.0.5 requires langchain-core>=1.0.0, but you have langchain-core 0.3.80 which is incompatible.\n",
            "langchain 1.1.0 requires langchain-core<2.0.0,>=1.1.0, but you have langchain-core 0.3.80 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.6.15 langchain-core-0.3.80 langchain_google_genai-2.0.10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "8ee1151c49dd438dbb8d33f2ed5756be"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage"
      ],
      "metadata": {
        "id": "Tu-iH6kEbsvD"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "import langchain_core\n",
        "import langchain_google_genai\n",
        "\n",
        "print(langchain.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdxirUMgKFvo",
        "outputId": "43b99339-9dbd-4a2e-89ed-62ccc26a7d3b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain>=0.3.0 langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qfinc2pKG9j",
        "outputId": "5710c36c-27a9-4ee9-b6d5-e3e087dc8cbb"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.globals import set_llm_cache\n",
        "set_llm_cache(None)"
      ],
      "metadata": {
        "id": "VwqZtY0yKUGE"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "model = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    api_key=api_key,\n",
        ")\n",
        "\n",
        "response = model.invoke([\n",
        "    HumanMessage(content=\"explain tree of thoughts with example\")\n",
        "])\n",
        "\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEBSzuJZKecv",
        "outputId": "f3b7b22f-30f7-48e9-a4ff-c0d2071e5589"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatGoogleGenerativeAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Human: explain tree of thoughts with example\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatGoogleGenerativeAI] [16.56s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"## Tree of Thoughts (ToT): A Powerful Problem-Solving Technique for Language Models\\n\\nTree of Thoughts (ToT) is a prompting technique designed to enhance the problem-solving capabilities of large language models (LLMs) like GPT-3, GPT-4, and others. It allows LLMs to explore multiple reasoning paths and evaluate different approaches before arriving at a final answer, similar to how humans brainstorm and refine ideas.\\n\\n**Key Concepts:**\\n\\n*   **Thoughts:** Individual units of reasoning or partial solutions generated by the LLM. These can be ideas, plans, evaluations, or critiques.\\n*   **Tree Structure:** The LLM organizes these thoughts into a tree-like structure, where each node represents a thought, and branches represent different possible continuations or refinements.\\n*   **Search Algorithm:** The LLM uses a search algorithm (like breadth-first search or depth-first search) to explore the tree of thoughts, evaluating the potential of each branch and discarding unpromising paths.\\n*   **Evaluation Function:**  A mechanism for the LLM to assess the value or potential of each thought, guiding the search towards promising solutions.\\n\\n**How ToT Works:**\\n\\n1.  **Problem Decomposition:** The problem is broken down into smaller, more manageable steps or sub-problems.\\n2.  **Thought Generation:** For each step, the LLM generates multiple possible \\\"thoughts\\\" - potential solutions or approaches.\\n3.  **Tree Construction:** These thoughts are organized into a tree structure, where each thought branches out into further possible thoughts.\\n4.  **Evaluation and Selection:** The LLM evaluates each thought based on its potential to lead to a successful solution.  This evaluation can be intrinsic (based on the LLM's internal knowledge) or extrinsic (based on external feedback or constraints).\\n5.  **Search and Refinement:** The LLM uses a search algorithm to explore the tree, focusing on promising branches and discarding less promising ones. This process may involve generating new thoughts, refining existing thoughts, or backtracking to explore alternative paths.\\n6.  **Solution Synthesis:** Once a satisfactory solution is found, the LLM synthesizes the thoughts along the chosen path into a coherent and complete answer.\\n\\n**Benefits of ToT:**\\n\\n*   **Improved Reasoning:**  Allows the LLM to explore multiple reasoning paths, leading to more robust and well-considered solutions.\\n*   **Handling Ambiguity:**  Enables the LLM to handle ambiguous problems by exploring different interpretations and potential solutions.\\n*   **Complex Problem Solving:**  Facilitates the solution of complex problems that require multiple steps and considerations.\\n*   **Increased Accuracy:**  Leads to more accurate and reliable results by reducing reliance on single, potentially flawed, reasoning paths.\\n\\n**Example:  The 24 Game**\\n\\nThe 24 Game is a mathematical puzzle where you are given four numbers and must use arithmetic operations (+, -, *, /) to reach 24.\\n\\n**Problem:** Given the numbers 4, 7, 8, and 1, find a solution to the 24 game.\\n\\n**ToT Approach:**\\n\\n1.  **Decomposition:** The problem is already somewhat decomposed, as we have four distinct numbers to work with.  We can think of each step as combining two numbers using an operation.\\n\\n2.  **Thought Generation (First Level):**\\n\\n    *   Thought 1: (4 + 7) = 11\\n    *   Thought 2: (4 - 7) = -3\\n    *   Thought 3: (4 * 7) = 28\\n    *   Thought 4: (4 / 7) = 0.57 (approximately)\\n    *   Thought 5: (7 + 8) = 15\\n    *   Thought 6: (7 - 8) = -1\\n    *   Thought 7: (7 * 8) = 56\\n    *   Thought 8: (7 / 8) = 0.875 (approximately)\\n    *   Thought 9: (8 + 1) = 9\\n    *   Thought 10: (8 - 1) = 7\\n    *   Thought 11: (8 * 1) = 8\\n    *   Thought 12: (8 / 1) = 8\\n    *   And so on...  (We can also consider combinations like 4+8, 4+1, etc.)\\n\\n3.  **Tree Construction (Simplified):** We can represent this as a tree where the root is the initial problem and each child node represents a possible first step.  Let's focus on Thought 1: (4 + 7) = 11.\\n\\n    ```\\n    Root:  4, 7, 8, 1 -> 24\\n\\n          |\\n          ------- Thought 1: 11, 8, 1\\n    ```\\n\\n4.  **Evaluation and Selection:**  Which of these initial thoughts seems promising?  We're looking for a path that gets us closer to 24.  Let's consider combining 11 with 8 and 1.  We'll evaluate based on how close we are to 24.\\n\\n5.  **Thought Generation (Second Level - Branching from Thought 1):**\\n\\n    *   Thought 1.1: (11 + 8) = 19 (Leaves us with 19, 1)\\n    *   Thought 1.2: (11 - 8) = 3  (Leaves us with 3, 1)\\n    *   Thought 1.3: (11 * 8) = 88 (Leaves us with 88, 1)\\n    *   Thought 1.4: (11 / 8) = 1.375 (Leaves us with 1.375, 1)\\n    *   Thought 1.5: (11 + 1) = 12 (Leaves us with 12, 8)\\n    *   Thought 1.6: (11 - 1) = 10 (Leaves us with 10, 8)\\n    *   Thought 1.7: (11 * 1) = 11 (Leaves us with 11, 8)\\n    *   Thought 1.8: (11 / 1) = 11 (Leaves us with 11, 8)\\n\\n    Now the tree looks like this (simplified):\\n\\n    ```\\n    Root:  4, 7, 8, 1 -> 24\\n\\n          |\\n          ------- Thought 1: 11, 8, 1\\n                 |\\n                 ------- Thought 1.1: 19, 1\\n                 |\\n                 ------- Thought 1.2: 3, 1\\n                 |\\n                 ------- Thought 1.5: 12, 8\\n                 |\\n                 ------- ... other branches ...\\n    ```\\n\\n6.  **Search and Refinement:**\\n\\n    *   Let's explore Thought 1.5 (12, 8).  We can see that 12 * 2 = 24, and 8 / 4 = 2.  So, let's backtrack and try a different initial thought.\\n\\n    *   Go back to the Root.  Let's consider Thought 10: (8 - 1) = 7.  That leaves us with 4, 7, 7.\\n\\n    *   Now we have: Thought 10: 7, 4, 7\\n\\n    *   We can generate: Thought 10.1: (7 + 7) = 14.  Leaves us with 14, 4.\\n\\n    *   Thought 10.2: (7 - 7) = 0. Leaves us with 0, 4.  This seems unlikely.\\n\\n    *   Thought 10.3: (7 * 7) = 49.  Leaves us with 49, 4. Unlikely.\\n\\n    *   Let's explore Thought 10.1 (14, 4).  We can see that 24 - 14 = 10.\\n\\n    *   Backtrack again!  Let's try a different initial thought.\\n\\n    *   Consider:  (7 - 4) = 3. Leaves us with 3, 8, 1.\\n\\n    *   Thought:  3 * 8 = 24.  We have the 24!  But what about the 1?\\n\\n    *   **AHA!**  (7 - 4) * (8 / 1) = 24\\n\\n7.  **Solution Synthesis:** The LLM would synthesize the steps it took to arrive at the solution:\\n\\n    1.  Calculate (7 - 4) = 3\\n    2.  Calculate (8 / 1) = 8\\n    3.  Calculate 3 * 8 = 24\\n\\n    Therefore, the solution is (7 - 4) * (8 / 1) = 24\\n\\n**Implementation Details:**\\n\\n*   **Prompting:** The LLM is prompted with instructions to generate multiple thoughts, evaluate them, and explore different branches. Special keywords or delimiters can be used to structure the thoughts and guide the search process.\\n*   **Search Algorithms:**  Breadth-first search, depth-first search, and Monte Carlo Tree Search (MCTS) are common search algorithms used in ToT.\\n*   **Evaluation Functions:**  The evaluation function can be based on heuristics, learned models, or external feedback. For example, in the 24 game, the evaluation function could be based on the absolute difference between the current value and 24.\\n\\n**In Summary:**\\n\\nTree of Thoughts empowers LLMs to tackle complex problems by breaking them down into smaller steps, exploring multiple reasoning paths, and evaluating the potential of each approach. This technique allows LLMs to reason more effectively, handle ambiguity, and arrive at more accurate and reliable solutions. While the above example is simplified, it showcases the core principles of ToT. In practice, the LLM would be guided by carefully crafted prompts and evaluation functions to efficiently explore the tree and find the optimal solution.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"STOP\",\n",
            "          \"safety_ratings\": []\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"## Tree of Thoughts (ToT): A Powerful Problem-Solving Technique for Language Models\\n\\nTree of Thoughts (ToT) is a prompting technique designed to enhance the problem-solving capabilities of large language models (LLMs) like GPT-3, GPT-4, and others. It allows LLMs to explore multiple reasoning paths and evaluate different approaches before arriving at a final answer, similar to how humans brainstorm and refine ideas.\\n\\n**Key Concepts:**\\n\\n*   **Thoughts:** Individual units of reasoning or partial solutions generated by the LLM. These can be ideas, plans, evaluations, or critiques.\\n*   **Tree Structure:** The LLM organizes these thoughts into a tree-like structure, where each node represents a thought, and branches represent different possible continuations or refinements.\\n*   **Search Algorithm:** The LLM uses a search algorithm (like breadth-first search or depth-first search) to explore the tree of thoughts, evaluating the potential of each branch and discarding unpromising paths.\\n*   **Evaluation Function:**  A mechanism for the LLM to assess the value or potential of each thought, guiding the search towards promising solutions.\\n\\n**How ToT Works:**\\n\\n1.  **Problem Decomposition:** The problem is broken down into smaller, more manageable steps or sub-problems.\\n2.  **Thought Generation:** For each step, the LLM generates multiple possible \\\"thoughts\\\" - potential solutions or approaches.\\n3.  **Tree Construction:** These thoughts are organized into a tree structure, where each thought branches out into further possible thoughts.\\n4.  **Evaluation and Selection:** The LLM evaluates each thought based on its potential to lead to a successful solution.  This evaluation can be intrinsic (based on the LLM's internal knowledge) or extrinsic (based on external feedback or constraints).\\n5.  **Search and Refinement:** The LLM uses a search algorithm to explore the tree, focusing on promising branches and discarding less promising ones. This process may involve generating new thoughts, refining existing thoughts, or backtracking to explore alternative paths.\\n6.  **Solution Synthesis:** Once a satisfactory solution is found, the LLM synthesizes the thoughts along the chosen path into a coherent and complete answer.\\n\\n**Benefits of ToT:**\\n\\n*   **Improved Reasoning:**  Allows the LLM to explore multiple reasoning paths, leading to more robust and well-considered solutions.\\n*   **Handling Ambiguity:**  Enables the LLM to handle ambiguous problems by exploring different interpretations and potential solutions.\\n*   **Complex Problem Solving:**  Facilitates the solution of complex problems that require multiple steps and considerations.\\n*   **Increased Accuracy:**  Leads to more accurate and reliable results by reducing reliance on single, potentially flawed, reasoning paths.\\n\\n**Example:  The 24 Game**\\n\\nThe 24 Game is a mathematical puzzle where you are given four numbers and must use arithmetic operations (+, -, *, /) to reach 24.\\n\\n**Problem:** Given the numbers 4, 7, 8, and 1, find a solution to the 24 game.\\n\\n**ToT Approach:**\\n\\n1.  **Decomposition:** The problem is already somewhat decomposed, as we have four distinct numbers to work with.  We can think of each step as combining two numbers using an operation.\\n\\n2.  **Thought Generation (First Level):**\\n\\n    *   Thought 1: (4 + 7) = 11\\n    *   Thought 2: (4 - 7) = -3\\n    *   Thought 3: (4 * 7) = 28\\n    *   Thought 4: (4 / 7) = 0.57 (approximately)\\n    *   Thought 5: (7 + 8) = 15\\n    *   Thought 6: (7 - 8) = -1\\n    *   Thought 7: (7 * 8) = 56\\n    *   Thought 8: (7 / 8) = 0.875 (approximately)\\n    *   Thought 9: (8 + 1) = 9\\n    *   Thought 10: (8 - 1) = 7\\n    *   Thought 11: (8 * 1) = 8\\n    *   Thought 12: (8 / 1) = 8\\n    *   And so on...  (We can also consider combinations like 4+8, 4+1, etc.)\\n\\n3.  **Tree Construction (Simplified):** We can represent this as a tree where the root is the initial problem and each child node represents a possible first step.  Let's focus on Thought 1: (4 + 7) = 11.\\n\\n    ```\\n    Root:  4, 7, 8, 1 -> 24\\n\\n          |\\n          ------- Thought 1: 11, 8, 1\\n    ```\\n\\n4.  **Evaluation and Selection:**  Which of these initial thoughts seems promising?  We're looking for a path that gets us closer to 24.  Let's consider combining 11 with 8 and 1.  We'll evaluate based on how close we are to 24.\\n\\n5.  **Thought Generation (Second Level - Branching from Thought 1):**\\n\\n    *   Thought 1.1: (11 + 8) = 19 (Leaves us with 19, 1)\\n    *   Thought 1.2: (11 - 8) = 3  (Leaves us with 3, 1)\\n    *   Thought 1.3: (11 * 8) = 88 (Leaves us with 88, 1)\\n    *   Thought 1.4: (11 / 8) = 1.375 (Leaves us with 1.375, 1)\\n    *   Thought 1.5: (11 + 1) = 12 (Leaves us with 12, 8)\\n    *   Thought 1.6: (11 - 1) = 10 (Leaves us with 10, 8)\\n    *   Thought 1.7: (11 * 1) = 11 (Leaves us with 11, 8)\\n    *   Thought 1.8: (11 / 1) = 11 (Leaves us with 11, 8)\\n\\n    Now the tree looks like this (simplified):\\n\\n    ```\\n    Root:  4, 7, 8, 1 -> 24\\n\\n          |\\n          ------- Thought 1: 11, 8, 1\\n                 |\\n                 ------- Thought 1.1: 19, 1\\n                 |\\n                 ------- Thought 1.2: 3, 1\\n                 |\\n                 ------- Thought 1.5: 12, 8\\n                 |\\n                 ------- ... other branches ...\\n    ```\\n\\n6.  **Search and Refinement:**\\n\\n    *   Let's explore Thought 1.5 (12, 8).  We can see that 12 * 2 = 24, and 8 / 4 = 2.  So, let's backtrack and try a different initial thought.\\n\\n    *   Go back to the Root.  Let's consider Thought 10: (8 - 1) = 7.  That leaves us with 4, 7, 7.\\n\\n    *   Now we have: Thought 10: 7, 4, 7\\n\\n    *   We can generate: Thought 10.1: (7 + 7) = 14.  Leaves us with 14, 4.\\n\\n    *   Thought 10.2: (7 - 7) = 0. Leaves us with 0, 4.  This seems unlikely.\\n\\n    *   Thought 10.3: (7 * 7) = 49.  Leaves us with 49, 4. Unlikely.\\n\\n    *   Let's explore Thought 10.1 (14, 4).  We can see that 24 - 14 = 10.\\n\\n    *   Backtrack again!  Let's try a different initial thought.\\n\\n    *   Consider:  (7 - 4) = 3. Leaves us with 3, 8, 1.\\n\\n    *   Thought:  3 * 8 = 24.  We have the 24!  But what about the 1?\\n\\n    *   **AHA!**  (7 - 4) * (8 / 1) = 24\\n\\n7.  **Solution Synthesis:** The LLM would synthesize the steps it took to arrive at the solution:\\n\\n    1.  Calculate (7 - 4) = 3\\n    2.  Calculate (8 / 1) = 8\\n    3.  Calculate 3 * 8 = 24\\n\\n    Therefore, the solution is (7 - 4) * (8 / 1) = 24\\n\\n**Implementation Details:**\\n\\n*   **Prompting:** The LLM is prompted with instructions to generate multiple thoughts, evaluate them, and explore different branches. Special keywords or delimiters can be used to structure the thoughts and guide the search process.\\n*   **Search Algorithms:**  Breadth-first search, depth-first search, and Monte Carlo Tree Search (MCTS) are common search algorithms used in ToT.\\n*   **Evaluation Functions:**  The evaluation function can be based on heuristics, learned models, or external feedback. For example, in the 24 game, the evaluation function could be based on the absolute difference between the current value and 24.\\n\\n**In Summary:**\\n\\nTree of Thoughts empowers LLMs to tackle complex problems by breaking them down into smaller steps, exploring multiple reasoning paths, and evaluating the potential of each approach. This technique allows LLMs to reason more effectively, handle ambiguity, and arrive at more accurate and reliable solutions. While the above example is simplified, it showcases the core principles of ToT. In practice, the LLM would be guided by carefully crafted prompts and evaluation functions to efficiently explore the tree and find the optimal solution.\",\n",
            "            \"response_metadata\": {\n",
            "              \"prompt_feedback\": {\n",
            "                \"block_reason\": 0,\n",
            "                \"safety_ratings\": []\n",
            "              },\n",
            "              \"finish_reason\": \"STOP\",\n",
            "              \"safety_ratings\": []\n",
            "            },\n",
            "            \"type\": \"ai\",\n",
            "            \"id\": \"run--4a6ff05c-3b90-49f1-bcd8-5dd12ad56495-0\",\n",
            "            \"usage_metadata\": {\n",
            "              \"input_tokens\": 6,\n",
            "              \"output_tokens\": 2241,\n",
            "              \"total_tokens\": 2247,\n",
            "              \"input_token_details\": {\n",
            "                \"cache_read\": 0\n",
            "              }\n",
            "            },\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"prompt_feedback\": {\n",
            "      \"block_reason\": 0,\n",
            "      \"safety_ratings\": []\n",
            "    }\n",
            "  },\n",
            "  \"run\": null,\n",
            "  \"type\": \"LLMResult\"\n",
            "}\n",
            "## Tree of Thoughts (ToT): A Powerful Problem-Solving Technique for Language Models\n",
            "\n",
            "Tree of Thoughts (ToT) is a prompting technique designed to enhance the problem-solving capabilities of large language models (LLMs) like GPT-3, GPT-4, and others. It allows LLMs to explore multiple reasoning paths and evaluate different approaches before arriving at a final answer, similar to how humans brainstorm and refine ideas.\n",
            "\n",
            "**Key Concepts:**\n",
            "\n",
            "*   **Thoughts:** Individual units of reasoning or partial solutions generated by the LLM. These can be ideas, plans, evaluations, or critiques.\n",
            "*   **Tree Structure:** The LLM organizes these thoughts into a tree-like structure, where each node represents a thought, and branches represent different possible continuations or refinements.\n",
            "*   **Search Algorithm:** The LLM uses a search algorithm (like breadth-first search or depth-first search) to explore the tree of thoughts, evaluating the potential of each branch and discarding unpromising paths.\n",
            "*   **Evaluation Function:**  A mechanism for the LLM to assess the value or potential of each thought, guiding the search towards promising solutions.\n",
            "\n",
            "**How ToT Works:**\n",
            "\n",
            "1.  **Problem Decomposition:** The problem is broken down into smaller, more manageable steps or sub-problems.\n",
            "2.  **Thought Generation:** For each step, the LLM generates multiple possible \"thoughts\" - potential solutions or approaches.\n",
            "3.  **Tree Construction:** These thoughts are organized into a tree structure, where each thought branches out into further possible thoughts.\n",
            "4.  **Evaluation and Selection:** The LLM evaluates each thought based on its potential to lead to a successful solution.  This evaluation can be intrinsic (based on the LLM's internal knowledge) or extrinsic (based on external feedback or constraints).\n",
            "5.  **Search and Refinement:** The LLM uses a search algorithm to explore the tree, focusing on promising branches and discarding less promising ones. This process may involve generating new thoughts, refining existing thoughts, or backtracking to explore alternative paths.\n",
            "6.  **Solution Synthesis:** Once a satisfactory solution is found, the LLM synthesizes the thoughts along the chosen path into a coherent and complete answer.\n",
            "\n",
            "**Benefits of ToT:**\n",
            "\n",
            "*   **Improved Reasoning:**  Allows the LLM to explore multiple reasoning paths, leading to more robust and well-considered solutions.\n",
            "*   **Handling Ambiguity:**  Enables the LLM to handle ambiguous problems by exploring different interpretations and potential solutions.\n",
            "*   **Complex Problem Solving:**  Facilitates the solution of complex problems that require multiple steps and considerations.\n",
            "*   **Increased Accuracy:**  Leads to more accurate and reliable results by reducing reliance on single, potentially flawed, reasoning paths.\n",
            "\n",
            "**Example:  The 24 Game**\n",
            "\n",
            "The 24 Game is a mathematical puzzle where you are given four numbers and must use arithmetic operations (+, -, *, /) to reach 24.\n",
            "\n",
            "**Problem:** Given the numbers 4, 7, 8, and 1, find a solution to the 24 game.\n",
            "\n",
            "**ToT Approach:**\n",
            "\n",
            "1.  **Decomposition:** The problem is already somewhat decomposed, as we have four distinct numbers to work with.  We can think of each step as combining two numbers using an operation.\n",
            "\n",
            "2.  **Thought Generation (First Level):**\n",
            "\n",
            "    *   Thought 1: (4 + 7) = 11\n",
            "    *   Thought 2: (4 - 7) = -3\n",
            "    *   Thought 3: (4 * 7) = 28\n",
            "    *   Thought 4: (4 / 7) = 0.57 (approximately)\n",
            "    *   Thought 5: (7 + 8) = 15\n",
            "    *   Thought 6: (7 - 8) = -1\n",
            "    *   Thought 7: (7 * 8) = 56\n",
            "    *   Thought 8: (7 / 8) = 0.875 (approximately)\n",
            "    *   Thought 9: (8 + 1) = 9\n",
            "    *   Thought 10: (8 - 1) = 7\n",
            "    *   Thought 11: (8 * 1) = 8\n",
            "    *   Thought 12: (8 / 1) = 8\n",
            "    *   And so on...  (We can also consider combinations like 4+8, 4+1, etc.)\n",
            "\n",
            "3.  **Tree Construction (Simplified):** We can represent this as a tree where the root is the initial problem and each child node represents a possible first step.  Let's focus on Thought 1: (4 + 7) = 11.\n",
            "\n",
            "    ```\n",
            "    Root:  4, 7, 8, 1 -> 24\n",
            "\n",
            "          |\n",
            "          ------- Thought 1: 11, 8, 1\n",
            "    ```\n",
            "\n",
            "4.  **Evaluation and Selection:**  Which of these initial thoughts seems promising?  We're looking for a path that gets us closer to 24.  Let's consider combining 11 with 8 and 1.  We'll evaluate based on how close we are to 24.\n",
            "\n",
            "5.  **Thought Generation (Second Level - Branching from Thought 1):**\n",
            "\n",
            "    *   Thought 1.1: (11 + 8) = 19 (Leaves us with 19, 1)\n",
            "    *   Thought 1.2: (11 - 8) = 3  (Leaves us with 3, 1)\n",
            "    *   Thought 1.3: (11 * 8) = 88 (Leaves us with 88, 1)\n",
            "    *   Thought 1.4: (11 / 8) = 1.375 (Leaves us with 1.375, 1)\n",
            "    *   Thought 1.5: (11 + 1) = 12 (Leaves us with 12, 8)\n",
            "    *   Thought 1.6: (11 - 1) = 10 (Leaves us with 10, 8)\n",
            "    *   Thought 1.7: (11 * 1) = 11 (Leaves us with 11, 8)\n",
            "    *   Thought 1.8: (11 / 1) = 11 (Leaves us with 11, 8)\n",
            "\n",
            "    Now the tree looks like this (simplified):\n",
            "\n",
            "    ```\n",
            "    Root:  4, 7, 8, 1 -> 24\n",
            "\n",
            "          |\n",
            "          ------- Thought 1: 11, 8, 1\n",
            "                 |\n",
            "                 ------- Thought 1.1: 19, 1\n",
            "                 |\n",
            "                 ------- Thought 1.2: 3, 1\n",
            "                 |\n",
            "                 ------- Thought 1.5: 12, 8\n",
            "                 |\n",
            "                 ------- ... other branches ...\n",
            "    ```\n",
            "\n",
            "6.  **Search and Refinement:**\n",
            "\n",
            "    *   Let's explore Thought 1.5 (12, 8).  We can see that 12 * 2 = 24, and 8 / 4 = 2.  So, let's backtrack and try a different initial thought.\n",
            "\n",
            "    *   Go back to the Root.  Let's consider Thought 10: (8 - 1) = 7.  That leaves us with 4, 7, 7.\n",
            "\n",
            "    *   Now we have: Thought 10: 7, 4, 7\n",
            "\n",
            "    *   We can generate: Thought 10.1: (7 + 7) = 14.  Leaves us with 14, 4.\n",
            "\n",
            "    *   Thought 10.2: (7 - 7) = 0. Leaves us with 0, 4.  This seems unlikely.\n",
            "\n",
            "    *   Thought 10.3: (7 * 7) = 49.  Leaves us with 49, 4. Unlikely.\n",
            "\n",
            "    *   Let's explore Thought 10.1 (14, 4).  We can see that 24 - 14 = 10.\n",
            "\n",
            "    *   Backtrack again!  Let's try a different initial thought.\n",
            "\n",
            "    *   Consider:  (7 - 4) = 3. Leaves us with 3, 8, 1.\n",
            "\n",
            "    *   Thought:  3 * 8 = 24.  We have the 24!  But what about the 1?\n",
            "\n",
            "    *   **AHA!**  (7 - 4) * (8 / 1) = 24\n",
            "\n",
            "7.  **Solution Synthesis:** The LLM would synthesize the steps it took to arrive at the solution:\n",
            "\n",
            "    1.  Calculate (7 - 4) = 3\n",
            "    2.  Calculate (8 / 1) = 8\n",
            "    3.  Calculate 3 * 8 = 24\n",
            "\n",
            "    Therefore, the solution is (7 - 4) * (8 / 1) = 24\n",
            "\n",
            "**Implementation Details:**\n",
            "\n",
            "*   **Prompting:** The LLM is prompted with instructions to generate multiple thoughts, evaluate them, and explore different branches. Special keywords or delimiters can be used to structure the thoughts and guide the search process.\n",
            "*   **Search Algorithms:**  Breadth-first search, depth-first search, and Monte Carlo Tree Search (MCTS) are common search algorithms used in ToT.\n",
            "*   **Evaluation Functions:**  The evaluation function can be based on heuristics, learned models, or external feedback. For example, in the 24 game, the evaluation function could be based on the absolute difference between the current value and 24.\n",
            "\n",
            "**In Summary:**\n",
            "\n",
            "Tree of Thoughts empowers LLMs to tackle complex problems by breaking them down into smaller steps, exploring multiple reasoning paths, and evaluating the potential of each approach. This technique allows LLMs to reason more effectively, handle ambiguity, and arrive at more accurate and reliable solutions. While the above example is simplified, it showcases the core principles of ToT. In practice, the LLM would be guided by carefully crafted prompts and evaluation functions to efficiently explore the tree and find the optimal solution.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#multiple job offers in hand\n",
        "prompt = '''\n",
        "I have 3 jobs and need to decide one to take. help me think through this systematically\n",
        "by exploring ways to evaluate.\n",
        "job A: Big tech company , 7 lakhs/annum, long hours, great benefits\n",
        "job B: start up 6 lakhs/annum, flexible hours, equity options, uncertain future\n",
        "job C: local company, 6.5 lakhs/annum, good work-life balance, limited growth\n",
        "think about this from multiple view points and help me decide\n",
        "what i want to explore:\n",
        "view point1: financial comarision(salary, benefit, long-term earning potential)\n",
        "view point2: career growth opportunities\n",
        "view point3: work-life balance and personal happiness\n",
        "view point4: risk vs stability\n",
        "final synthesis: whicj job best matched my priorties\n",
        "'''\n",
        "response = model.invoke([HumanMessage(content = prompt)])\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "dnEerwza1XfG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f30a0939-bef4-4ce0-de13-1984ebec307d"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatGoogleGenerativeAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Human: \\nI have 3 jobs and need to decide one to take. help me think through this systematically\\nby exploring ways to evaluate.\\njob A: Big tech company , 7 lakhs/annum, long hours, great benefits\\njob B: start up 6 lakhs/annum, flexible hours, equity options, uncertain future\\njob C: local company, 6.5 lakhs/annum, good work-life balance, limited growth\\nthink about this from multiple view points and help me decide\\nwhat i want to explore:\\nview point1: financial comarision(salary, benefit, long-term earning potential)\\nview point2: career growth opportunities\\nview point3: work-life balance and personal happiness\\nview point4: risk vs stability\\nfinal synthesis: whicj job best matched my priorties\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatGoogleGenerativeAI] [16.57s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"Okay, let's systematically break down these three job offers to help you make the best decision, considering your priorities.\\n\\n**1. Financial Comparison (Salary, Benefits, Long-Term Earning Potential)**\\n\\n*   **Job A (Big Tech):**\\n    *   *Salary:* ₹7 lakhs/annum\\n    *   *Benefits:* \\\"Great benefits\\\" - This is vague.  We need specifics!  Ask for details on:\\n        *   Health insurance (coverage levels, premiums)\\n        *   Retirement plan (matching contributions, vesting schedule)\\n        *   Paid time off (vacation, sick leave, holidays)\\n        *   Other perks (gym memberships, food stipends, professional development budget, stock options/RSUs)\\n    *   *Long-Term Earning Potential:*  Potentially high. Big tech companies often have well-defined career ladders and opportunities for promotions and salary increases.  Factor in potential bonuses and stock options/RSUs (if offered). Also, consider the value of the experience gained at a big tech company – it can open doors to future opportunities, even if you leave.\\n*   **Job B (Startup):**\\n    *   *Salary:* ₹6 lakhs/annum\\n    *   *Benefits:*  Focus on the specifics of the equity options.\\n        *   *Equity Options:* This is a HUGE variable.  Get the details!  How many options are you granted? What's the strike price? What's the vesting schedule?  What's the company's valuation?  Equity could be worth nothing, or it could be worth a lot if the startup is successful.  Get an expert to evaluate the terms if you're unsure.  Don't treat equity as guaranteed money.\\n        *   Other benefits - often startups have less comprehensive benefits packages than larger companies.\\n    *   *Long-Term Earning Potential:*  Highly variable.  If the startup succeeds, your equity could be very valuable, and your salary could increase rapidly.  However, the startup could also fail, leaving you with nothing.\\n*   **Job C (Local Company):**\\n    *   *Salary:* ₹6.5 lakhs/annum\\n    *   *Benefits:* Assume standard for a local company.  Clarify details on health insurance, retirement, and paid time off.\\n    *   *Long-Term Earning Potential:*  Likely moderate.  Salary increases might be more predictable but less dramatic than in the other two options.  Limited growth potential suggests fewer opportunities for promotions into higher-paying roles.\\n\\n**Action Items for Financial Comparison:**\\n\\n1.  **Quantify the \\\"Great Benefits\\\" of Job A.**  Get specifics in writing.\\n2.  **Thoroughly understand the equity options offered by Job B.**  Seek expert advice if needed.\\n3.  **Clarify the benefits package offered by Job C.**\\n4.  **Research typical salary growth trajectories for similar roles at each type of company.** (Use sites like Glassdoor, Payscale, or Salary.com.)\\n\\n**2. Career Growth Opportunities**\\n\\n*   **Job A (Big Tech):**\\n    *   *Pros:* Structured training programs, mentorship opportunities, exposure to cutting-edge technologies, well-defined career paths, networking opportunities with industry leaders.\\n    *   *Cons:*  Can be competitive, may get pigeonholed into a specific role early on, potential for bureaucracy and slow decision-making.\\n*   **Job B (Startup):**\\n    *   *Pros:*  Opportunity to wear many hats, gain experience in various areas of the business, high impact potential, fast-paced learning environment, direct influence on the company's direction.\\n    *   *Cons:*  Limited structure and training, potential for chaos and lack of resources, risk of the company failing and halting your career progression.\\n*   **Job C (Local Company):**\\n    *   *Pros:*  Stable environment, opportunity to become an expert in a specific area, potentially less pressure to constantly innovate.\\n    *   *Cons:*  Limited opportunities for advancement, potential for stagnation, may not be exposed to the latest technologies or industry trends.\\n\\n**Action Items for Career Growth:**\\n\\n1.  **Ask about training and development opportunities during the interview process.**\\n2.  **Research the career paths of people who started in similar roles at each company.**  (LinkedIn can be helpful.)\\n3.  **Consider your preferred learning style.** Do you thrive in structured environments, or do you prefer to learn by doing and figuring things out on your own?\\n\\n**3. Work-Life Balance and Personal Happiness**\\n\\n*   **Job A (Big Tech):**\\n    *   *Pros:*  Potentially good benefits that support well-being (depending on the company).\\n    *   *Cons:*  Long hours can lead to burnout and negatively impact personal life.  High-pressure environment.\\n*   **Job B (Startup):**\\n    *   *Pros:*  Flexible hours can be a major plus, allowing you to tailor your work schedule to your personal needs.\\n    *   *Cons:*  \\\"Flexible\\\" doesn't always mean \\\"less work.\\\"  Startups often demand a lot of your time and energy, especially in the early stages.  The uncertain future can also be stressful.\\n*   **Job C (Local Company):**\\n    *   *Pros:*  Good work-life balance is a major advantage, allowing you to prioritize personal interests and relationships.  Less stress.\\n    *   *Cons:*  May feel less challenging or stimulating if you're ambitious.\\n\\n**Action Items for Work-Life Balance:**\\n\\n1.  **Ask about typical work hours and expectations during the interview process.**\\n2.  **Try to speak to current employees at each company to get a realistic sense of the work-life balance.**\\n3.  **Reflect on your personal priorities and how much time you're willing to dedicate to work versus other aspects of your life.**\\n\\n**4. Risk vs. Stability**\\n\\n*   **Job A (Big Tech):**\\n    *   *Risk:* Low.  Big tech companies are generally stable and offer job security.\\n    *   *Stability:* High.\\n*   **Job B (Startup):**\\n    *   *Risk:* High.  Startups have a high failure rate.\\n    *   *Stability:* Low.\\n*   **Job C (Local Company):**\\n    *   *Risk:* Moderate.  More stable than a startup, but less secure than a big tech company.\\n    *   *Stability:* Moderate.\\n\\n**Action Items for Risk vs. Stability:**\\n\\n1.  **Assess your personal risk tolerance.** Are you comfortable with uncertainty, or do you prefer a more predictable environment?\\n2.  **Consider your financial situation.** Do you have savings to fall back on if you lose your job?\\n3.  **Research the stability of the specific local company.**  How long has it been in business?  What is its financial performance?\\n\\n**Final Synthesis: Which Job Best Matches My Priorities?**\\n\\nTo make the final decision, you need to weigh each factor against your personal priorities. Here's a framework:\\n\\n1.  **Rank Your Priorities:**  Assign a weight (e.g., out of 10) to each of the four viewpoints:\\n    *   Financial Comparison: (Weight)\\n    *   Career Growth Opportunities: (Weight)\\n    *   Work-Life Balance and Personal Happiness: (Weight)\\n    *   Risk vs. Stability: (Weight)\\n    *   *Make sure the weights add up to 10!*\\n\\n2.  **Score Each Job:**  For each viewpoint, score each job on a scale of 1 to 5 (1 = poor, 5 = excellent) *based on the information you've gathered*.\\n\\n3.  **Calculate Weighted Scores:** Multiply each score by the corresponding weight.\\n\\n4.  **Total Scores:** Add up the weighted scores for each job.\\n\\n5.  **Decision:** The job with the highest total score is the best match for your priorities.\\n\\n**Example:**\\n\\nLet's say your priorities are:\\n\\n*   Financial Comparison: 3\\n*   Career Growth Opportunities: 3\\n*   Work-Life Balance and Personal Happiness: 4\\n*   Risk vs. Stability: 0 (you are ok taking risks)\\n\\nAnd your scores for each job are:\\n\\n| Viewpoint                              | Job A (Big Tech) | Job B (Startup) | Job C (Local) |\\n| --------------------------------------- | ---------------- | ---------------- | ------------- |\\n| Financial Comparison                    | 4                | 3                | 3             |\\n| Career Growth Opportunities            | 5                | 4                | 2             |\\n| Work-Life Balance and Personal Happiness | 2                | 4                | 5             |\\n| Risk vs. Stability                      | 5                | 1                | 3             |\\n\\n**Calculations:**\\n\\n*   **Job A:** (4\\\\*3) + (5\\\\*3) + (2\\\\*4) + (5\\\\*0) = 12 + 15 + 8 + 0 = 35\\n*   **Job B:** (3\\\\*3) + (4\\\\*3) + (4\\\\*4) + (1\\\\*0) = 9 + 12 + 16 + 0 = 37\\n*   **Job C:** (3\\\\*3) + (2\\\\*3) + (5\\\\*4) + (3\\\\*0) = 9 + 6 + 20 + 0 = 35\\n\\n**In this example, Job B (Startup) would be the best choice, even though it has higher risk. Because you indicated risk is not a factor.**\\n\\n**Important Considerations:**\\n\\n*   **Gut Feeling:**  Don't ignore your intuition.  If a job feels wrong, even if the numbers add up, it might not be the right fit.\\n*   **Company Culture:** Try to get a sense of the company culture at each organization.  Do you feel like you would fit in and be happy working there?\\n*   **Negotiation:**  Don't be afraid to negotiate the terms of the job offer.  You might be able to improve the salary, benefits, or equity package.\\n\\nBy systematically evaluating these factors and weighing them against your personal priorities, you can make a more informed and confident decision about which job to accept. Good luck! Let me know if you have any other questions.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"STOP\",\n",
            "          \"safety_ratings\": []\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"Okay, let's systematically break down these three job offers to help you make the best decision, considering your priorities.\\n\\n**1. Financial Comparison (Salary, Benefits, Long-Term Earning Potential)**\\n\\n*   **Job A (Big Tech):**\\n    *   *Salary:* ₹7 lakhs/annum\\n    *   *Benefits:* \\\"Great benefits\\\" - This is vague.  We need specifics!  Ask for details on:\\n        *   Health insurance (coverage levels, premiums)\\n        *   Retirement plan (matching contributions, vesting schedule)\\n        *   Paid time off (vacation, sick leave, holidays)\\n        *   Other perks (gym memberships, food stipends, professional development budget, stock options/RSUs)\\n    *   *Long-Term Earning Potential:*  Potentially high. Big tech companies often have well-defined career ladders and opportunities for promotions and salary increases.  Factor in potential bonuses and stock options/RSUs (if offered). Also, consider the value of the experience gained at a big tech company – it can open doors to future opportunities, even if you leave.\\n*   **Job B (Startup):**\\n    *   *Salary:* ₹6 lakhs/annum\\n    *   *Benefits:*  Focus on the specifics of the equity options.\\n        *   *Equity Options:* This is a HUGE variable.  Get the details!  How many options are you granted? What's the strike price? What's the vesting schedule?  What's the company's valuation?  Equity could be worth nothing, or it could be worth a lot if the startup is successful.  Get an expert to evaluate the terms if you're unsure.  Don't treat equity as guaranteed money.\\n        *   Other benefits - often startups have less comprehensive benefits packages than larger companies.\\n    *   *Long-Term Earning Potential:*  Highly variable.  If the startup succeeds, your equity could be very valuable, and your salary could increase rapidly.  However, the startup could also fail, leaving you with nothing.\\n*   **Job C (Local Company):**\\n    *   *Salary:* ₹6.5 lakhs/annum\\n    *   *Benefits:* Assume standard for a local company.  Clarify details on health insurance, retirement, and paid time off.\\n    *   *Long-Term Earning Potential:*  Likely moderate.  Salary increases might be more predictable but less dramatic than in the other two options.  Limited growth potential suggests fewer opportunities for promotions into higher-paying roles.\\n\\n**Action Items for Financial Comparison:**\\n\\n1.  **Quantify the \\\"Great Benefits\\\" of Job A.**  Get specifics in writing.\\n2.  **Thoroughly understand the equity options offered by Job B.**  Seek expert advice if needed.\\n3.  **Clarify the benefits package offered by Job C.**\\n4.  **Research typical salary growth trajectories for similar roles at each type of company.** (Use sites like Glassdoor, Payscale, or Salary.com.)\\n\\n**2. Career Growth Opportunities**\\n\\n*   **Job A (Big Tech):**\\n    *   *Pros:* Structured training programs, mentorship opportunities, exposure to cutting-edge technologies, well-defined career paths, networking opportunities with industry leaders.\\n    *   *Cons:*  Can be competitive, may get pigeonholed into a specific role early on, potential for bureaucracy and slow decision-making.\\n*   **Job B (Startup):**\\n    *   *Pros:*  Opportunity to wear many hats, gain experience in various areas of the business, high impact potential, fast-paced learning environment, direct influence on the company's direction.\\n    *   *Cons:*  Limited structure and training, potential for chaos and lack of resources, risk of the company failing and halting your career progression.\\n*   **Job C (Local Company):**\\n    *   *Pros:*  Stable environment, opportunity to become an expert in a specific area, potentially less pressure to constantly innovate.\\n    *   *Cons:*  Limited opportunities for advancement, potential for stagnation, may not be exposed to the latest technologies or industry trends.\\n\\n**Action Items for Career Growth:**\\n\\n1.  **Ask about training and development opportunities during the interview process.**\\n2.  **Research the career paths of people who started in similar roles at each company.**  (LinkedIn can be helpful.)\\n3.  **Consider your preferred learning style.** Do you thrive in structured environments, or do you prefer to learn by doing and figuring things out on your own?\\n\\n**3. Work-Life Balance and Personal Happiness**\\n\\n*   **Job A (Big Tech):**\\n    *   *Pros:*  Potentially good benefits that support well-being (depending on the company).\\n    *   *Cons:*  Long hours can lead to burnout and negatively impact personal life.  High-pressure environment.\\n*   **Job B (Startup):**\\n    *   *Pros:*  Flexible hours can be a major plus, allowing you to tailor your work schedule to your personal needs.\\n    *   *Cons:*  \\\"Flexible\\\" doesn't always mean \\\"less work.\\\"  Startups often demand a lot of your time and energy, especially in the early stages.  The uncertain future can also be stressful.\\n*   **Job C (Local Company):**\\n    *   *Pros:*  Good work-life balance is a major advantage, allowing you to prioritize personal interests and relationships.  Less stress.\\n    *   *Cons:*  May feel less challenging or stimulating if you're ambitious.\\n\\n**Action Items for Work-Life Balance:**\\n\\n1.  **Ask about typical work hours and expectations during the interview process.**\\n2.  **Try to speak to current employees at each company to get a realistic sense of the work-life balance.**\\n3.  **Reflect on your personal priorities and how much time you're willing to dedicate to work versus other aspects of your life.**\\n\\n**4. Risk vs. Stability**\\n\\n*   **Job A (Big Tech):**\\n    *   *Risk:* Low.  Big tech companies are generally stable and offer job security.\\n    *   *Stability:* High.\\n*   **Job B (Startup):**\\n    *   *Risk:* High.  Startups have a high failure rate.\\n    *   *Stability:* Low.\\n*   **Job C (Local Company):**\\n    *   *Risk:* Moderate.  More stable than a startup, but less secure than a big tech company.\\n    *   *Stability:* Moderate.\\n\\n**Action Items for Risk vs. Stability:**\\n\\n1.  **Assess your personal risk tolerance.** Are you comfortable with uncertainty, or do you prefer a more predictable environment?\\n2.  **Consider your financial situation.** Do you have savings to fall back on if you lose your job?\\n3.  **Research the stability of the specific local company.**  How long has it been in business?  What is its financial performance?\\n\\n**Final Synthesis: Which Job Best Matches My Priorities?**\\n\\nTo make the final decision, you need to weigh each factor against your personal priorities. Here's a framework:\\n\\n1.  **Rank Your Priorities:**  Assign a weight (e.g., out of 10) to each of the four viewpoints:\\n    *   Financial Comparison: (Weight)\\n    *   Career Growth Opportunities: (Weight)\\n    *   Work-Life Balance and Personal Happiness: (Weight)\\n    *   Risk vs. Stability: (Weight)\\n    *   *Make sure the weights add up to 10!*\\n\\n2.  **Score Each Job:**  For each viewpoint, score each job on a scale of 1 to 5 (1 = poor, 5 = excellent) *based on the information you've gathered*.\\n\\n3.  **Calculate Weighted Scores:** Multiply each score by the corresponding weight.\\n\\n4.  **Total Scores:** Add up the weighted scores for each job.\\n\\n5.  **Decision:** The job with the highest total score is the best match for your priorities.\\n\\n**Example:**\\n\\nLet's say your priorities are:\\n\\n*   Financial Comparison: 3\\n*   Career Growth Opportunities: 3\\n*   Work-Life Balance and Personal Happiness: 4\\n*   Risk vs. Stability: 0 (you are ok taking risks)\\n\\nAnd your scores for each job are:\\n\\n| Viewpoint                              | Job A (Big Tech) | Job B (Startup) | Job C (Local) |\\n| --------------------------------------- | ---------------- | ---------------- | ------------- |\\n| Financial Comparison                    | 4                | 3                | 3             |\\n| Career Growth Opportunities            | 5                | 4                | 2             |\\n| Work-Life Balance and Personal Happiness | 2                | 4                | 5             |\\n| Risk vs. Stability                      | 5                | 1                | 3             |\\n\\n**Calculations:**\\n\\n*   **Job A:** (4\\\\*3) + (5\\\\*3) + (2\\\\*4) + (5\\\\*0) = 12 + 15 + 8 + 0 = 35\\n*   **Job B:** (3\\\\*3) + (4\\\\*3) + (4\\\\*4) + (1\\\\*0) = 9 + 12 + 16 + 0 = 37\\n*   **Job C:** (3\\\\*3) + (2\\\\*3) + (5\\\\*4) + (3\\\\*0) = 9 + 6 + 20 + 0 = 35\\n\\n**In this example, Job B (Startup) would be the best choice, even though it has higher risk. Because you indicated risk is not a factor.**\\n\\n**Important Considerations:**\\n\\n*   **Gut Feeling:**  Don't ignore your intuition.  If a job feels wrong, even if the numbers add up, it might not be the right fit.\\n*   **Company Culture:** Try to get a sense of the company culture at each organization.  Do you feel like you would fit in and be happy working there?\\n*   **Negotiation:**  Don't be afraid to negotiate the terms of the job offer.  You might be able to improve the salary, benefits, or equity package.\\n\\nBy systematically evaluating these factors and weighing them against your personal priorities, you can make a more informed and confident decision about which job to accept. Good luck! Let me know if you have any other questions.\",\n",
            "            \"response_metadata\": {\n",
            "              \"prompt_feedback\": {\n",
            "                \"block_reason\": 0,\n",
            "                \"safety_ratings\": []\n",
            "              },\n",
            "              \"finish_reason\": \"STOP\",\n",
            "              \"safety_ratings\": []\n",
            "            },\n",
            "            \"type\": \"ai\",\n",
            "            \"id\": \"run--56bf325a-4a39-454f-8822-43ef9e7604f2-0\",\n",
            "            \"usage_metadata\": {\n",
            "              \"input_tokens\": 174,\n",
            "              \"output_tokens\": 2256,\n",
            "              \"total_tokens\": 2430,\n",
            "              \"input_token_details\": {\n",
            "                \"cache_read\": 0\n",
            "              }\n",
            "            },\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"prompt_feedback\": {\n",
            "      \"block_reason\": 0,\n",
            "      \"safety_ratings\": []\n",
            "    }\n",
            "  },\n",
            "  \"run\": null,\n",
            "  \"type\": \"LLMResult\"\n",
            "}\n",
            "Okay, let's systematically break down these three job offers to help you make the best decision, considering your priorities.\n",
            "\n",
            "**1. Financial Comparison (Salary, Benefits, Long-Term Earning Potential)**\n",
            "\n",
            "*   **Job A (Big Tech):**\n",
            "    *   *Salary:* ₹7 lakhs/annum\n",
            "    *   *Benefits:* \"Great benefits\" - This is vague.  We need specifics!  Ask for details on:\n",
            "        *   Health insurance (coverage levels, premiums)\n",
            "        *   Retirement plan (matching contributions, vesting schedule)\n",
            "        *   Paid time off (vacation, sick leave, holidays)\n",
            "        *   Other perks (gym memberships, food stipends, professional development budget, stock options/RSUs)\n",
            "    *   *Long-Term Earning Potential:*  Potentially high. Big tech companies often have well-defined career ladders and opportunities for promotions and salary increases.  Factor in potential bonuses and stock options/RSUs (if offered). Also, consider the value of the experience gained at a big tech company – it can open doors to future opportunities, even if you leave.\n",
            "*   **Job B (Startup):**\n",
            "    *   *Salary:* ₹6 lakhs/annum\n",
            "    *   *Benefits:*  Focus on the specifics of the equity options.\n",
            "        *   *Equity Options:* This is a HUGE variable.  Get the details!  How many options are you granted? What's the strike price? What's the vesting schedule?  What's the company's valuation?  Equity could be worth nothing, or it could be worth a lot if the startup is successful.  Get an expert to evaluate the terms if you're unsure.  Don't treat equity as guaranteed money.\n",
            "        *   Other benefits - often startups have less comprehensive benefits packages than larger companies.\n",
            "    *   *Long-Term Earning Potential:*  Highly variable.  If the startup succeeds, your equity could be very valuable, and your salary could increase rapidly.  However, the startup could also fail, leaving you with nothing.\n",
            "*   **Job C (Local Company):**\n",
            "    *   *Salary:* ₹6.5 lakhs/annum\n",
            "    *   *Benefits:* Assume standard for a local company.  Clarify details on health insurance, retirement, and paid time off.\n",
            "    *   *Long-Term Earning Potential:*  Likely moderate.  Salary increases might be more predictable but less dramatic than in the other two options.  Limited growth potential suggests fewer opportunities for promotions into higher-paying roles.\n",
            "\n",
            "**Action Items for Financial Comparison:**\n",
            "\n",
            "1.  **Quantify the \"Great Benefits\" of Job A.**  Get specifics in writing.\n",
            "2.  **Thoroughly understand the equity options offered by Job B.**  Seek expert advice if needed.\n",
            "3.  **Clarify the benefits package offered by Job C.**\n",
            "4.  **Research typical salary growth trajectories for similar roles at each type of company.** (Use sites like Glassdoor, Payscale, or Salary.com.)\n",
            "\n",
            "**2. Career Growth Opportunities**\n",
            "\n",
            "*   **Job A (Big Tech):**\n",
            "    *   *Pros:* Structured training programs, mentorship opportunities, exposure to cutting-edge technologies, well-defined career paths, networking opportunities with industry leaders.\n",
            "    *   *Cons:*  Can be competitive, may get pigeonholed into a specific role early on, potential for bureaucracy and slow decision-making.\n",
            "*   **Job B (Startup):**\n",
            "    *   *Pros:*  Opportunity to wear many hats, gain experience in various areas of the business, high impact potential, fast-paced learning environment, direct influence on the company's direction.\n",
            "    *   *Cons:*  Limited structure and training, potential for chaos and lack of resources, risk of the company failing and halting your career progression.\n",
            "*   **Job C (Local Company):**\n",
            "    *   *Pros:*  Stable environment, opportunity to become an expert in a specific area, potentially less pressure to constantly innovate.\n",
            "    *   *Cons:*  Limited opportunities for advancement, potential for stagnation, may not be exposed to the latest technologies or industry trends.\n",
            "\n",
            "**Action Items for Career Growth:**\n",
            "\n",
            "1.  **Ask about training and development opportunities during the interview process.**\n",
            "2.  **Research the career paths of people who started in similar roles at each company.**  (LinkedIn can be helpful.)\n",
            "3.  **Consider your preferred learning style.** Do you thrive in structured environments, or do you prefer to learn by doing and figuring things out on your own?\n",
            "\n",
            "**3. Work-Life Balance and Personal Happiness**\n",
            "\n",
            "*   **Job A (Big Tech):**\n",
            "    *   *Pros:*  Potentially good benefits that support well-being (depending on the company).\n",
            "    *   *Cons:*  Long hours can lead to burnout and negatively impact personal life.  High-pressure environment.\n",
            "*   **Job B (Startup):**\n",
            "    *   *Pros:*  Flexible hours can be a major plus, allowing you to tailor your work schedule to your personal needs.\n",
            "    *   *Cons:*  \"Flexible\" doesn't always mean \"less work.\"  Startups often demand a lot of your time and energy, especially in the early stages.  The uncertain future can also be stressful.\n",
            "*   **Job C (Local Company):**\n",
            "    *   *Pros:*  Good work-life balance is a major advantage, allowing you to prioritize personal interests and relationships.  Less stress.\n",
            "    *   *Cons:*  May feel less challenging or stimulating if you're ambitious.\n",
            "\n",
            "**Action Items for Work-Life Balance:**\n",
            "\n",
            "1.  **Ask about typical work hours and expectations during the interview process.**\n",
            "2.  **Try to speak to current employees at each company to get a realistic sense of the work-life balance.**\n",
            "3.  **Reflect on your personal priorities and how much time you're willing to dedicate to work versus other aspects of your life.**\n",
            "\n",
            "**4. Risk vs. Stability**\n",
            "\n",
            "*   **Job A (Big Tech):**\n",
            "    *   *Risk:* Low.  Big tech companies are generally stable and offer job security.\n",
            "    *   *Stability:* High.\n",
            "*   **Job B (Startup):**\n",
            "    *   *Risk:* High.  Startups have a high failure rate.\n",
            "    *   *Stability:* Low.\n",
            "*   **Job C (Local Company):**\n",
            "    *   *Risk:* Moderate.  More stable than a startup, but less secure than a big tech company.\n",
            "    *   *Stability:* Moderate.\n",
            "\n",
            "**Action Items for Risk vs. Stability:**\n",
            "\n",
            "1.  **Assess your personal risk tolerance.** Are you comfortable with uncertainty, or do you prefer a more predictable environment?\n",
            "2.  **Consider your financial situation.** Do you have savings to fall back on if you lose your job?\n",
            "3.  **Research the stability of the specific local company.**  How long has it been in business?  What is its financial performance?\n",
            "\n",
            "**Final Synthesis: Which Job Best Matches My Priorities?**\n",
            "\n",
            "To make the final decision, you need to weigh each factor against your personal priorities. Here's a framework:\n",
            "\n",
            "1.  **Rank Your Priorities:**  Assign a weight (e.g., out of 10) to each of the four viewpoints:\n",
            "    *   Financial Comparison: (Weight)\n",
            "    *   Career Growth Opportunities: (Weight)\n",
            "    *   Work-Life Balance and Personal Happiness: (Weight)\n",
            "    *   Risk vs. Stability: (Weight)\n",
            "    *   *Make sure the weights add up to 10!*\n",
            "\n",
            "2.  **Score Each Job:**  For each viewpoint, score each job on a scale of 1 to 5 (1 = poor, 5 = excellent) *based on the information you've gathered*.\n",
            "\n",
            "3.  **Calculate Weighted Scores:** Multiply each score by the corresponding weight.\n",
            "\n",
            "4.  **Total Scores:** Add up the weighted scores for each job.\n",
            "\n",
            "5.  **Decision:** The job with the highest total score is the best match for your priorities.\n",
            "\n",
            "**Example:**\n",
            "\n",
            "Let's say your priorities are:\n",
            "\n",
            "*   Financial Comparison: 3\n",
            "*   Career Growth Opportunities: 3\n",
            "*   Work-Life Balance and Personal Happiness: 4\n",
            "*   Risk vs. Stability: 0 (you are ok taking risks)\n",
            "\n",
            "And your scores for each job are:\n",
            "\n",
            "| Viewpoint                              | Job A (Big Tech) | Job B (Startup) | Job C (Local) |\n",
            "| --------------------------------------- | ---------------- | ---------------- | ------------- |\n",
            "| Financial Comparison                    | 4                | 3                | 3             |\n",
            "| Career Growth Opportunities            | 5                | 4                | 2             |\n",
            "| Work-Life Balance and Personal Happiness | 2                | 4                | 5             |\n",
            "| Risk vs. Stability                      | 5                | 1                | 3             |\n",
            "\n",
            "**Calculations:**\n",
            "\n",
            "*   **Job A:** (4\\*3) + (5\\*3) + (2\\*4) + (5\\*0) = 12 + 15 + 8 + 0 = 35\n",
            "*   **Job B:** (3\\*3) + (4\\*3) + (4\\*4) + (1\\*0) = 9 + 12 + 16 + 0 = 37\n",
            "*   **Job C:** (3\\*3) + (2\\*3) + (5\\*4) + (3\\*0) = 9 + 6 + 20 + 0 = 35\n",
            "\n",
            "**In this example, Job B (Startup) would be the best choice, even though it has higher risk. Because you indicated risk is not a factor.**\n",
            "\n",
            "**Important Considerations:**\n",
            "\n",
            "*   **Gut Feeling:**  Don't ignore your intuition.  If a job feels wrong, even if the numbers add up, it might not be the right fit.\n",
            "*   **Company Culture:** Try to get a sense of the company culture at each organization.  Do you feel like you would fit in and be happy working there?\n",
            "*   **Negotiation:**  Don't be afraid to negotiate the terms of the job offer.  You might be able to improve the salary, benefits, or equity package.\n",
            "\n",
            "By systematically evaluating these factors and weighing them against your personal priorities, you can make a more informed and confident decision about which job to accept. Good luck! Let me know if you have any other questions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "i have exam in 3 weeks and need a stydy plan. please explore different ways to organize my study time and recommand the best approach.\n",
        "exam:\n",
        "-python for data science (easiest for me, scored 90% in previos exam)\n",
        "-statistics (hardest for me, scored 60% in previous exam)\n",
        "-machine learning 1(easiest for me, scored 80% in previous exam)\n",
        "-unsupervised learning(medium difficult, socred 72% in previous exam)\n",
        "consider different studies stratagies and tell me which would work the best.\n",
        "\n",
        " i want you to explore different stratagies as listed below.\n",
        "\n",
        " stratedy1: study hardest subject first\n",
        " stratedy2: study easiest subject first\n",
        " stratedy3: study medium difficult\n",
        "\n",
        " evaluation: which strategy fits my learning style and maximizes my grades?.\n",
        " '''\n",
        "response = model.invoke([HumanMessage(content = prompt)])\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "X5by2fp99BIY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfd1087e-270c-48c6-94bd-f2af347b65aa"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatGoogleGenerativeAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Human: \\ni have exam in 3 weeks and need a stydy plan. please explore different ways to organize my study time and recommand the best approach.\\nexam:\\n-python for data science (easiest for me, scored 90% in previos exam)\\n-statistics (hardest for me, scored 60% in previous exam)\\n-machine learning 1(easiest for me, scored 80% in previous exam)\\n-unsupervised learning(medium difficult, socred 72% in previous exam)\\nconsider different studies stratagies and tell me which would work the best.\\n\\n i want you to explore different stratagies as listed below.\\n\\n stratedy1: study hardest subject first\\n stratedy2: study easiest subject first\\n stratedy3: study medium difficult\\n\\n evaluation: which strategy fits my learning style and maximizes my grades?.\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatGoogleGenerativeAI] [14.09s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"Okay, let's craft a study plan for your exam, keeping your strengths and weaknesses in mind, and evaluating different strategies.  We'll break down the next three weeks and consider the pros and cons of each strategy you suggested.\\n\\n**Understanding Your Situation**\\n\\n*   **Timeframe:** 3 weeks\\n*   **Subjects:**\\n    *   Python for Data Science (Easy, 90% previous)\\n    *   Statistics (Hard, 60% previous)\\n    *   Machine Learning 1 (Easy, 80% previous)\\n    *   Unsupervised Learning (Medium, 72% previous)\\n*   **Key Insight:** Statistics is your biggest hurdle. Python and Machine Learning 1 are your strengths. Unsupervised Learning is a good middle ground.\\n\\n**Study Strategies Exploration & Evaluation**\\n\\nHere's a breakdown of each strategy, its pros and cons in your specific context, and a recommended schedule:\\n\\n**Strategy 1: Study Hardest Subject First (Statistics)**\\n\\n*   **Description:** Dedicate the most time and energy at the beginning of your study period to Statistics.\\n*   **Pros:**\\n    *   **Tackles the biggest challenge head-on:** You address your weakest area when you're fresh and motivated.\\n    *   **Reduces anxiety:** Getting a handle on Statistics early can lower overall exam stress.\\n    *   **Potential for compounding knowledge:** A solid foundation in Statistics will likely benefit your understanding of Machine Learning and Unsupervised Learning.\\n*   **Cons:**\\n    *   **Can be demoralizing:** Starting with a difficult subject can lead to frustration and burnout if you don't see progress quickly.\\n    *   **May neglect easier subjects:** Focusing solely on Statistics for too long could cause you to lose ground on topics you already know well.\\n*   **Recommended Schedule (Strategy 1):**\\n    *   **Week 1:**  **Focus: Statistics (60%)**.  Python (20%), Unsupervised Learning(20%).\\n        *   Start with foundational concepts: Descriptive statistics, probability, distributions.\\n        *   Work through practice problems.  Identify areas of specific weakness.\\n        *   Use multiple resources: Textbook, online courses (Khan Academy, StatQuest), practice exams.\\n        *   Allocate specific days for Statistics.\\n        *   Review Python basics (data structures, libraries used in data science) for 1-2 hours every other day.\\n        *   Review the basics of unsupervised learning.\\n    *   **Week 2:** **Focus: Statistics (40%)**.  Unsupervised Learning (30%), Machine Learning 1 (30%)\\n        *   Continue working on Statistics, focusing on areas where you struggled in Week 1 (hypothesis testing, regression, etc.).\\n        *   Begin studying Unsupervised Learning in more detail.\\n        *   Review Machine Learning 1 (algorithms, evaluation metrics).\\n    *   **Week 3:** **Focus: Review and Practice (All Subjects)**\\n        *   **First Half:**  Practice exams covering all subjects.  Analyze your performance to identify weak areas.\\n        *   **Second Half:**  Targeted review based on practice exam results.  Focus on filling knowledge gaps.  Re-do practice problems in areas where you struggled.  Light review of Python.\\n\\n**Strategy 2: Study Easiest Subject First (Python for Data Science or Machine Learning 1)**\\n\\n*   **Description:** Start with Python or Machine Learning 1 to build confidence and momentum.\\n*   **Pros:**\\n    *   **Boosts confidence:**  Starting with something you know well can make you feel more prepared and motivated.\\n    *   **Easy win:**  Quickly reviewing Python or Machine Learning 1 can free up mental space for tackling more challenging subjects.\\n    *   **Can reinforce concepts:**  Reviewing Python can help you remember important programming skills relevant to other areas.\\n*   **Cons:**\\n    *   **Procrastination risk:**  Spending too much time on easy subjects can lead you to postpone studying Statistics.\\n    *   **False sense of security:**  Feeling confident in Python might make you underestimate the effort required for other subjects.\\n    *   **May not address the most pressing need:**  Delaying Statistics could lead to increased anxiety and last-minute cramming.\\n*   **Recommended Schedule (Strategy 2):**\\n    *   **Week 1:**  **Focus: Python (40%)**. Machine Learning 1 (30%), Unsupervised Learning (30%)\\n        *   Quickly review all Python concepts, focusing on areas relevant to data science.\\n        *   Review Machine Learning 1 and Unsupervised Learning.\\n    *   **Week 2:**  **Focus: Statistics (60%)**. Unsupervised Learning (40%)\\n        *   Dive into Statistics, using the same approach as in Strategy 1 (foundational concepts, practice problems, multiple resources).\\n        *   Continue studying Unsupervised Learning.\\n    *   **Week 3:** **Focus: Review and Practice (All Subjects)**\\n        *   Similar to Strategy 1: Practice exams, analyze performance, targeted review.\\n\\n**Strategy 3: Study Medium Difficulty First (Unsupervised Learning)**\\n\\n*   **Description:** Start with Unsupervised Learning, which falls in the middle in terms of difficulty.\\n*   **Pros:**\\n    *   **Balanced approach:**  Allows you to ease into studying without immediately facing the most challenging material.\\n    *   **Builds momentum:**  Success in Unsupervised Learning can motivate you to tackle Statistics.\\n    *   **Connects concepts:**  Unsupervised Learning often builds on concepts from Statistics and Machine Learning, providing a good bridge between the two.\\n*   **Cons:**\\n    *   **Doesn't address the biggest challenge immediately:** Delaying Statistics could still lead to anxiety.\\n    *   **May not be the most efficient use of time:**  Starting with a medium-difficulty subject might not provide the biggest return on investment.\\n*   **Recommended Schedule (Strategy 3):**\\n    *   **Week 1:**  **Focus: Unsupervised Learning (40%)**.  Python (30%), Machine Learning 1 (30%)\\n        *   Dive deep into Unsupervised Learning concepts and algorithms (clustering, dimensionality reduction, etc.).\\n        *   Review Python and Machine Learning 1.\\n    *   **Week 2:**  **Focus: Statistics (60%)**. Unsupervised Learning (40%)\\n        *   Focus on Statistics, using the same approach as in Strategy 1.\\n        *   Continue studying Unsupervised Learning.\\n    *   **Week 3:** **Focus: Review and Practice (All Subjects)**\\n        *   Similar to Strategy 1: Practice exams, analyze performance, targeted review.\\n\\n**Evaluation and Recommendation**\\n\\nGiven your situation, **Strategy 1 (Hardest Subject First - Statistics) is the most likely to maximize your grades.** Here's why:\\n\\n*   **Addresses your biggest weakness:**  Your previous score in Statistics indicates it's a significant area for improvement.  Tackling it head-on gives you the most time to master the concepts.\\n*   **Reduces anxiety:** Overcoming the Statistics hurdle early will reduce overall exam stress and improve your confidence.\\n*   **Foundation for other subjects:** A strong understanding of Statistics is crucial for both Machine Learning and Unsupervised Learning.\\n*   **Forces discipline:**  Starting with a difficult subject requires discipline and focus, which can translate to better study habits overall.\\n\\n**Important Considerations for all Strategies:**\\n\\n*   **Active Recall and Spaced Repetition:**  Don't just passively read notes or watch videos. Use active recall techniques (flashcards, practice questions) to test your understanding.  Space out your review sessions to improve long-term retention.\\n*   **Practice Exams:**  Take at least two full-length practice exams under realistic exam conditions (time limits, no distractions).\\n*   **Identify and Address Weaknesses:**  After each practice exam, carefully analyze your performance.  Identify specific topics where you struggled and focus your review efforts on those areas.\\n*   **Breaks and Self-Care:**  Don't burn yourself out.  Schedule regular breaks to rest and recharge. Get enough sleep, eat healthy, and exercise to maintain your physical and mental well-being.\\n*   **Adaptability:** Be prepared to adjust your study plan as needed. If you find that a particular strategy isn't working, don't be afraid to switch gears.\\n\\n**In summary:**\\n\\n1.  **Prioritize Statistics using Strategy 1.**\\n2.  **Use active recall and spaced repetition.**\\n3.  **Take practice exams and analyze your performance.**\\n4.  **Schedule breaks and prioritize self-care.**\\n5.  **Be flexible and adapt your plan as needed.**\\n\\nGood luck with your exams! Let me know if you have any other questions.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"STOP\",\n",
            "          \"safety_ratings\": []\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"Okay, let's craft a study plan for your exam, keeping your strengths and weaknesses in mind, and evaluating different strategies.  We'll break down the next three weeks and consider the pros and cons of each strategy you suggested.\\n\\n**Understanding Your Situation**\\n\\n*   **Timeframe:** 3 weeks\\n*   **Subjects:**\\n    *   Python for Data Science (Easy, 90% previous)\\n    *   Statistics (Hard, 60% previous)\\n    *   Machine Learning 1 (Easy, 80% previous)\\n    *   Unsupervised Learning (Medium, 72% previous)\\n*   **Key Insight:** Statistics is your biggest hurdle. Python and Machine Learning 1 are your strengths. Unsupervised Learning is a good middle ground.\\n\\n**Study Strategies Exploration & Evaluation**\\n\\nHere's a breakdown of each strategy, its pros and cons in your specific context, and a recommended schedule:\\n\\n**Strategy 1: Study Hardest Subject First (Statistics)**\\n\\n*   **Description:** Dedicate the most time and energy at the beginning of your study period to Statistics.\\n*   **Pros:**\\n    *   **Tackles the biggest challenge head-on:** You address your weakest area when you're fresh and motivated.\\n    *   **Reduces anxiety:** Getting a handle on Statistics early can lower overall exam stress.\\n    *   **Potential for compounding knowledge:** A solid foundation in Statistics will likely benefit your understanding of Machine Learning and Unsupervised Learning.\\n*   **Cons:**\\n    *   **Can be demoralizing:** Starting with a difficult subject can lead to frustration and burnout if you don't see progress quickly.\\n    *   **May neglect easier subjects:** Focusing solely on Statistics for too long could cause you to lose ground on topics you already know well.\\n*   **Recommended Schedule (Strategy 1):**\\n    *   **Week 1:**  **Focus: Statistics (60%)**.  Python (20%), Unsupervised Learning(20%).\\n        *   Start with foundational concepts: Descriptive statistics, probability, distributions.\\n        *   Work through practice problems.  Identify areas of specific weakness.\\n        *   Use multiple resources: Textbook, online courses (Khan Academy, StatQuest), practice exams.\\n        *   Allocate specific days for Statistics.\\n        *   Review Python basics (data structures, libraries used in data science) for 1-2 hours every other day.\\n        *   Review the basics of unsupervised learning.\\n    *   **Week 2:** **Focus: Statistics (40%)**.  Unsupervised Learning (30%), Machine Learning 1 (30%)\\n        *   Continue working on Statistics, focusing on areas where you struggled in Week 1 (hypothesis testing, regression, etc.).\\n        *   Begin studying Unsupervised Learning in more detail.\\n        *   Review Machine Learning 1 (algorithms, evaluation metrics).\\n    *   **Week 3:** **Focus: Review and Practice (All Subjects)**\\n        *   **First Half:**  Practice exams covering all subjects.  Analyze your performance to identify weak areas.\\n        *   **Second Half:**  Targeted review based on practice exam results.  Focus on filling knowledge gaps.  Re-do practice problems in areas where you struggled.  Light review of Python.\\n\\n**Strategy 2: Study Easiest Subject First (Python for Data Science or Machine Learning 1)**\\n\\n*   **Description:** Start with Python or Machine Learning 1 to build confidence and momentum.\\n*   **Pros:**\\n    *   **Boosts confidence:**  Starting with something you know well can make you feel more prepared and motivated.\\n    *   **Easy win:**  Quickly reviewing Python or Machine Learning 1 can free up mental space for tackling more challenging subjects.\\n    *   **Can reinforce concepts:**  Reviewing Python can help you remember important programming skills relevant to other areas.\\n*   **Cons:**\\n    *   **Procrastination risk:**  Spending too much time on easy subjects can lead you to postpone studying Statistics.\\n    *   **False sense of security:**  Feeling confident in Python might make you underestimate the effort required for other subjects.\\n    *   **May not address the most pressing need:**  Delaying Statistics could lead to increased anxiety and last-minute cramming.\\n*   **Recommended Schedule (Strategy 2):**\\n    *   **Week 1:**  **Focus: Python (40%)**. Machine Learning 1 (30%), Unsupervised Learning (30%)\\n        *   Quickly review all Python concepts, focusing on areas relevant to data science.\\n        *   Review Machine Learning 1 and Unsupervised Learning.\\n    *   **Week 2:**  **Focus: Statistics (60%)**. Unsupervised Learning (40%)\\n        *   Dive into Statistics, using the same approach as in Strategy 1 (foundational concepts, practice problems, multiple resources).\\n        *   Continue studying Unsupervised Learning.\\n    *   **Week 3:** **Focus: Review and Practice (All Subjects)**\\n        *   Similar to Strategy 1: Practice exams, analyze performance, targeted review.\\n\\n**Strategy 3: Study Medium Difficulty First (Unsupervised Learning)**\\n\\n*   **Description:** Start with Unsupervised Learning, which falls in the middle in terms of difficulty.\\n*   **Pros:**\\n    *   **Balanced approach:**  Allows you to ease into studying without immediately facing the most challenging material.\\n    *   **Builds momentum:**  Success in Unsupervised Learning can motivate you to tackle Statistics.\\n    *   **Connects concepts:**  Unsupervised Learning often builds on concepts from Statistics and Machine Learning, providing a good bridge between the two.\\n*   **Cons:**\\n    *   **Doesn't address the biggest challenge immediately:** Delaying Statistics could still lead to anxiety.\\n    *   **May not be the most efficient use of time:**  Starting with a medium-difficulty subject might not provide the biggest return on investment.\\n*   **Recommended Schedule (Strategy 3):**\\n    *   **Week 1:**  **Focus: Unsupervised Learning (40%)**.  Python (30%), Machine Learning 1 (30%)\\n        *   Dive deep into Unsupervised Learning concepts and algorithms (clustering, dimensionality reduction, etc.).\\n        *   Review Python and Machine Learning 1.\\n    *   **Week 2:**  **Focus: Statistics (60%)**. Unsupervised Learning (40%)\\n        *   Focus on Statistics, using the same approach as in Strategy 1.\\n        *   Continue studying Unsupervised Learning.\\n    *   **Week 3:** **Focus: Review and Practice (All Subjects)**\\n        *   Similar to Strategy 1: Practice exams, analyze performance, targeted review.\\n\\n**Evaluation and Recommendation**\\n\\nGiven your situation, **Strategy 1 (Hardest Subject First - Statistics) is the most likely to maximize your grades.** Here's why:\\n\\n*   **Addresses your biggest weakness:**  Your previous score in Statistics indicates it's a significant area for improvement.  Tackling it head-on gives you the most time to master the concepts.\\n*   **Reduces anxiety:** Overcoming the Statistics hurdle early will reduce overall exam stress and improve your confidence.\\n*   **Foundation for other subjects:** A strong understanding of Statistics is crucial for both Machine Learning and Unsupervised Learning.\\n*   **Forces discipline:**  Starting with a difficult subject requires discipline and focus, which can translate to better study habits overall.\\n\\n**Important Considerations for all Strategies:**\\n\\n*   **Active Recall and Spaced Repetition:**  Don't just passively read notes or watch videos. Use active recall techniques (flashcards, practice questions) to test your understanding.  Space out your review sessions to improve long-term retention.\\n*   **Practice Exams:**  Take at least two full-length practice exams under realistic exam conditions (time limits, no distractions).\\n*   **Identify and Address Weaknesses:**  After each practice exam, carefully analyze your performance.  Identify specific topics where you struggled and focus your review efforts on those areas.\\n*   **Breaks and Self-Care:**  Don't burn yourself out.  Schedule regular breaks to rest and recharge. Get enough sleep, eat healthy, and exercise to maintain your physical and mental well-being.\\n*   **Adaptability:** Be prepared to adjust your study plan as needed. If you find that a particular strategy isn't working, don't be afraid to switch gears.\\n\\n**In summary:**\\n\\n1.  **Prioritize Statistics using Strategy 1.**\\n2.  **Use active recall and spaced repetition.**\\n3.  **Take practice exams and analyze your performance.**\\n4.  **Schedule breaks and prioritize self-care.**\\n5.  **Be flexible and adapt your plan as needed.**\\n\\nGood luck with your exams! Let me know if you have any other questions.\",\n",
            "            \"response_metadata\": {\n",
            "              \"prompt_feedback\": {\n",
            "                \"block_reason\": 0,\n",
            "                \"safety_ratings\": []\n",
            "              },\n",
            "              \"finish_reason\": \"STOP\",\n",
            "              \"safety_ratings\": []\n",
            "            },\n",
            "            \"type\": \"ai\",\n",
            "            \"id\": \"run--393cba28-84ee-4d4d-825e-f3fef8301024-0\",\n",
            "            \"usage_metadata\": {\n",
            "              \"input_tokens\": 190,\n",
            "              \"output_tokens\": 1908,\n",
            "              \"total_tokens\": 2098,\n",
            "              \"input_token_details\": {\n",
            "                \"cache_read\": 0\n",
            "              }\n",
            "            },\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"prompt_feedback\": {\n",
            "      \"block_reason\": 0,\n",
            "      \"safety_ratings\": []\n",
            "    }\n",
            "  },\n",
            "  \"run\": null,\n",
            "  \"type\": \"LLMResult\"\n",
            "}\n",
            "Okay, let's craft a study plan for your exam, keeping your strengths and weaknesses in mind, and evaluating different strategies.  We'll break down the next three weeks and consider the pros and cons of each strategy you suggested.\n",
            "\n",
            "**Understanding Your Situation**\n",
            "\n",
            "*   **Timeframe:** 3 weeks\n",
            "*   **Subjects:**\n",
            "    *   Python for Data Science (Easy, 90% previous)\n",
            "    *   Statistics (Hard, 60% previous)\n",
            "    *   Machine Learning 1 (Easy, 80% previous)\n",
            "    *   Unsupervised Learning (Medium, 72% previous)\n",
            "*   **Key Insight:** Statistics is your biggest hurdle. Python and Machine Learning 1 are your strengths. Unsupervised Learning is a good middle ground.\n",
            "\n",
            "**Study Strategies Exploration & Evaluation**\n",
            "\n",
            "Here's a breakdown of each strategy, its pros and cons in your specific context, and a recommended schedule:\n",
            "\n",
            "**Strategy 1: Study Hardest Subject First (Statistics)**\n",
            "\n",
            "*   **Description:** Dedicate the most time and energy at the beginning of your study period to Statistics.\n",
            "*   **Pros:**\n",
            "    *   **Tackles the biggest challenge head-on:** You address your weakest area when you're fresh and motivated.\n",
            "    *   **Reduces anxiety:** Getting a handle on Statistics early can lower overall exam stress.\n",
            "    *   **Potential for compounding knowledge:** A solid foundation in Statistics will likely benefit your understanding of Machine Learning and Unsupervised Learning.\n",
            "*   **Cons:**\n",
            "    *   **Can be demoralizing:** Starting with a difficult subject can lead to frustration and burnout if you don't see progress quickly.\n",
            "    *   **May neglect easier subjects:** Focusing solely on Statistics for too long could cause you to lose ground on topics you already know well.\n",
            "*   **Recommended Schedule (Strategy 1):**\n",
            "    *   **Week 1:**  **Focus: Statistics (60%)**.  Python (20%), Unsupervised Learning(20%).\n",
            "        *   Start with foundational concepts: Descriptive statistics, probability, distributions.\n",
            "        *   Work through practice problems.  Identify areas of specific weakness.\n",
            "        *   Use multiple resources: Textbook, online courses (Khan Academy, StatQuest), practice exams.\n",
            "        *   Allocate specific days for Statistics.\n",
            "        *   Review Python basics (data structures, libraries used in data science) for 1-2 hours every other day.\n",
            "        *   Review the basics of unsupervised learning.\n",
            "    *   **Week 2:** **Focus: Statistics (40%)**.  Unsupervised Learning (30%), Machine Learning 1 (30%)\n",
            "        *   Continue working on Statistics, focusing on areas where you struggled in Week 1 (hypothesis testing, regression, etc.).\n",
            "        *   Begin studying Unsupervised Learning in more detail.\n",
            "        *   Review Machine Learning 1 (algorithms, evaluation metrics).\n",
            "    *   **Week 3:** **Focus: Review and Practice (All Subjects)**\n",
            "        *   **First Half:**  Practice exams covering all subjects.  Analyze your performance to identify weak areas.\n",
            "        *   **Second Half:**  Targeted review based on practice exam results.  Focus on filling knowledge gaps.  Re-do practice problems in areas where you struggled.  Light review of Python.\n",
            "\n",
            "**Strategy 2: Study Easiest Subject First (Python for Data Science or Machine Learning 1)**\n",
            "\n",
            "*   **Description:** Start with Python or Machine Learning 1 to build confidence and momentum.\n",
            "*   **Pros:**\n",
            "    *   **Boosts confidence:**  Starting with something you know well can make you feel more prepared and motivated.\n",
            "    *   **Easy win:**  Quickly reviewing Python or Machine Learning 1 can free up mental space for tackling more challenging subjects.\n",
            "    *   **Can reinforce concepts:**  Reviewing Python can help you remember important programming skills relevant to other areas.\n",
            "*   **Cons:**\n",
            "    *   **Procrastination risk:**  Spending too much time on easy subjects can lead you to postpone studying Statistics.\n",
            "    *   **False sense of security:**  Feeling confident in Python might make you underestimate the effort required for other subjects.\n",
            "    *   **May not address the most pressing need:**  Delaying Statistics could lead to increased anxiety and last-minute cramming.\n",
            "*   **Recommended Schedule (Strategy 2):**\n",
            "    *   **Week 1:**  **Focus: Python (40%)**. Machine Learning 1 (30%), Unsupervised Learning (30%)\n",
            "        *   Quickly review all Python concepts, focusing on areas relevant to data science.\n",
            "        *   Review Machine Learning 1 and Unsupervised Learning.\n",
            "    *   **Week 2:**  **Focus: Statistics (60%)**. Unsupervised Learning (40%)\n",
            "        *   Dive into Statistics, using the same approach as in Strategy 1 (foundational concepts, practice problems, multiple resources).\n",
            "        *   Continue studying Unsupervised Learning.\n",
            "    *   **Week 3:** **Focus: Review and Practice (All Subjects)**\n",
            "        *   Similar to Strategy 1: Practice exams, analyze performance, targeted review.\n",
            "\n",
            "**Strategy 3: Study Medium Difficulty First (Unsupervised Learning)**\n",
            "\n",
            "*   **Description:** Start with Unsupervised Learning, which falls in the middle in terms of difficulty.\n",
            "*   **Pros:**\n",
            "    *   **Balanced approach:**  Allows you to ease into studying without immediately facing the most challenging material.\n",
            "    *   **Builds momentum:**  Success in Unsupervised Learning can motivate you to tackle Statistics.\n",
            "    *   **Connects concepts:**  Unsupervised Learning often builds on concepts from Statistics and Machine Learning, providing a good bridge between the two.\n",
            "*   **Cons:**\n",
            "    *   **Doesn't address the biggest challenge immediately:** Delaying Statistics could still lead to anxiety.\n",
            "    *   **May not be the most efficient use of time:**  Starting with a medium-difficulty subject might not provide the biggest return on investment.\n",
            "*   **Recommended Schedule (Strategy 3):**\n",
            "    *   **Week 1:**  **Focus: Unsupervised Learning (40%)**.  Python (30%), Machine Learning 1 (30%)\n",
            "        *   Dive deep into Unsupervised Learning concepts and algorithms (clustering, dimensionality reduction, etc.).\n",
            "        *   Review Python and Machine Learning 1.\n",
            "    *   **Week 2:**  **Focus: Statistics (60%)**. Unsupervised Learning (40%)\n",
            "        *   Focus on Statistics, using the same approach as in Strategy 1.\n",
            "        *   Continue studying Unsupervised Learning.\n",
            "    *   **Week 3:** **Focus: Review and Practice (All Subjects)**\n",
            "        *   Similar to Strategy 1: Practice exams, analyze performance, targeted review.\n",
            "\n",
            "**Evaluation and Recommendation**\n",
            "\n",
            "Given your situation, **Strategy 1 (Hardest Subject First - Statistics) is the most likely to maximize your grades.** Here's why:\n",
            "\n",
            "*   **Addresses your biggest weakness:**  Your previous score in Statistics indicates it's a significant area for improvement.  Tackling it head-on gives you the most time to master the concepts.\n",
            "*   **Reduces anxiety:** Overcoming the Statistics hurdle early will reduce overall exam stress and improve your confidence.\n",
            "*   **Foundation for other subjects:** A strong understanding of Statistics is crucial for both Machine Learning and Unsupervised Learning.\n",
            "*   **Forces discipline:**  Starting with a difficult subject requires discipline and focus, which can translate to better study habits overall.\n",
            "\n",
            "**Important Considerations for all Strategies:**\n",
            "\n",
            "*   **Active Recall and Spaced Repetition:**  Don't just passively read notes or watch videos. Use active recall techniques (flashcards, practice questions) to test your understanding.  Space out your review sessions to improve long-term retention.\n",
            "*   **Practice Exams:**  Take at least two full-length practice exams under realistic exam conditions (time limits, no distractions).\n",
            "*   **Identify and Address Weaknesses:**  After each practice exam, carefully analyze your performance.  Identify specific topics where you struggled and focus your review efforts on those areas.\n",
            "*   **Breaks and Self-Care:**  Don't burn yourself out.  Schedule regular breaks to rest and recharge. Get enough sleep, eat healthy, and exercise to maintain your physical and mental well-being.\n",
            "*   **Adaptability:** Be prepared to adjust your study plan as needed. If you find that a particular strategy isn't working, don't be afraid to switch gears.\n",
            "\n",
            "**In summary:**\n",
            "\n",
            "1.  **Prioritize Statistics using Strategy 1.**\n",
            "2.  **Use active recall and spaced repetition.**\n",
            "3.  **Take practice exams and analyze your performance.**\n",
            "4.  **Schedule breaks and prioritize self-care.**\n",
            "5.  **Be flexible and adapt your plan as needed.**\n",
            "\n",
            "Good luck with your exams! Let me know if you have any other questions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Self consistency\n"
      ],
      "metadata": {
        "id": "yd-d6yap1Utn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "i want to solve a math problem in 3 diferent ways to check for consistency.\n",
        "problem: what is 15% of 240?\n",
        "method 1: [solve using percentage formula]\n",
        "method 2: [solve using decimal conversion]\n",
        "method 3: [solve using fraction approach]\n",
        "campare your answer- do they all match\n",
        "'''\n",
        "response = model.invoke([HumanMessage(content = prompt)])\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "-4bLuinCAI6v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39dea820-6ca9-4456-a4c9-2b53e5b8fb3a"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatGoogleGenerativeAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Human: \\ni want to solve a math problem in 3 diferent ways to check for consistency.\\nproblem: what is 15% of 240?\\nmethod 1: [solve using percentage formula]\\nmethod 2: [solve using decimal conversion]\\nmethod 3: [solve using fraction approach]\\ncampare your answer- do they all match\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatGoogleGenerativeAI] [3.46s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"Okay, let's solve the problem \\\"What is 15% of 240?\\\" using three different methods and then compare the results.\\n\\n**Method 1: Percentage Formula**\\n\\nThe percentage formula is:  Part = (Percentage / 100) * Whole\\n\\n*   Percentage = 15\\n*   Whole = 240\\n*   Part = ?\\n\\nPart = (15 / 100) * 240\\nPart = 0.15 * 240\\nPart = 36\\n\\n**Method 2: Decimal Conversion**\\n\\nConvert the percentage to a decimal by dividing by 100.  Then multiply the decimal by the whole number.\\n\\n*   15% = 15 / 100 = 0.15\\n*   Multiply the decimal by the whole: 0.15 * 240 = 36\\n\\n**Method 3: Fraction Approach**\\n\\nConvert the percentage to a fraction and then multiply the fraction by the whole number.\\n\\n*   15% = 15/100  We can simplify this fraction to 3/20.\\n*   Multiply the fraction by the whole number: (3/20) * 240 = (3 * 240) / 20 = 720 / 20 = 36\\n\\n**Comparison**\\n\\n*   Method 1: 36\\n*   Method 2: 36\\n*   Method 3: 36\\n\\n**Conclusion**\\n\\nYes, all three methods yield the same answer: 36.  Therefore, 15% of 240 is 36. This confirms the consistency of our calculations.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"STOP\",\n",
            "          \"safety_ratings\": []\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"Okay, let's solve the problem \\\"What is 15% of 240?\\\" using three different methods and then compare the results.\\n\\n**Method 1: Percentage Formula**\\n\\nThe percentage formula is:  Part = (Percentage / 100) * Whole\\n\\n*   Percentage = 15\\n*   Whole = 240\\n*   Part = ?\\n\\nPart = (15 / 100) * 240\\nPart = 0.15 * 240\\nPart = 36\\n\\n**Method 2: Decimal Conversion**\\n\\nConvert the percentage to a decimal by dividing by 100.  Then multiply the decimal by the whole number.\\n\\n*   15% = 15 / 100 = 0.15\\n*   Multiply the decimal by the whole: 0.15 * 240 = 36\\n\\n**Method 3: Fraction Approach**\\n\\nConvert the percentage to a fraction and then multiply the fraction by the whole number.\\n\\n*   15% = 15/100  We can simplify this fraction to 3/20.\\n*   Multiply the fraction by the whole number: (3/20) * 240 = (3 * 240) / 20 = 720 / 20 = 36\\n\\n**Comparison**\\n\\n*   Method 1: 36\\n*   Method 2: 36\\n*   Method 3: 36\\n\\n**Conclusion**\\n\\nYes, all three methods yield the same answer: 36.  Therefore, 15% of 240 is 36. This confirms the consistency of our calculations.\",\n",
            "            \"response_metadata\": {\n",
            "              \"prompt_feedback\": {\n",
            "                \"block_reason\": 0,\n",
            "                \"safety_ratings\": []\n",
            "              },\n",
            "              \"finish_reason\": \"STOP\",\n",
            "              \"safety_ratings\": []\n",
            "            },\n",
            "            \"type\": \"ai\",\n",
            "            \"id\": \"run--34141038-b023-4f4a-a0c6-df9b86445f4b-0\",\n",
            "            \"usage_metadata\": {\n",
            "              \"input_tokens\": 78,\n",
            "              \"output_tokens\": 377,\n",
            "              \"total_tokens\": 455,\n",
            "              \"input_token_details\": {\n",
            "                \"cache_read\": 0\n",
            "              }\n",
            "            },\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"prompt_feedback\": {\n",
            "      \"block_reason\": 0,\n",
            "      \"safety_ratings\": []\n",
            "    }\n",
            "  },\n",
            "  \"run\": null,\n",
            "  \"type\": \"LLMResult\"\n",
            "}\n",
            "Okay, let's solve the problem \"What is 15% of 240?\" using three different methods and then compare the results.\n",
            "\n",
            "**Method 1: Percentage Formula**\n",
            "\n",
            "The percentage formula is:  Part = (Percentage / 100) * Whole\n",
            "\n",
            "*   Percentage = 15\n",
            "*   Whole = 240\n",
            "*   Part = ?\n",
            "\n",
            "Part = (15 / 100) * 240\n",
            "Part = 0.15 * 240\n",
            "Part = 36\n",
            "\n",
            "**Method 2: Decimal Conversion**\n",
            "\n",
            "Convert the percentage to a decimal by dividing by 100.  Then multiply the decimal by the whole number.\n",
            "\n",
            "*   15% = 15 / 100 = 0.15\n",
            "*   Multiply the decimal by the whole: 0.15 * 240 = 36\n",
            "\n",
            "**Method 3: Fraction Approach**\n",
            "\n",
            "Convert the percentage to a fraction and then multiply the fraction by the whole number.\n",
            "\n",
            "*   15% = 15/100  We can simplify this fraction to 3/20.\n",
            "*   Multiply the fraction by the whole number: (3/20) * 240 = (3 * 240) / 20 = 720 / 20 = 36\n",
            "\n",
            "**Comparison**\n",
            "\n",
            "*   Method 1: 36\n",
            "*   Method 2: 36\n",
            "*   Method 3: 36\n",
            "\n",
            "**Conclusion**\n",
            "\n",
            "Yes, all three methods yield the same answer: 36.  Therefore, 15% of 240 is 36. This confirms the consistency of our calculations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### reasoning problems"
      ],
      "metadata": {
        "id": "1KjWHa2_Cd7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "I want to analyze this logic problem from 3 different angles to ensure consistency:\n",
        "problem: if all roses are flowers and some flowers are red, can we conclude that some roses are red?\n",
        "analysis1: use formal logic rules\n",
        "analysis2: use everyday reasoning\n",
        "analysis3: use examples to test the conclusion\n",
        "do all the three approaches give me the same results?\n",
        "'''\n",
        "response = model.invoke([HumanMessage(content = prompt)])\n",
        "print(response.content)\n"
      ],
      "metadata": {
        "id": "M23Y7jP8Cc_M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a95d171-2472-4a2f-8417-67c9538898f9"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatGoogleGenerativeAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Human: \\nI want to analyze this logic problem from 3 different angles to ensure consistency:\\nproblem: if all roses are flowers and some flowers are red, can we conclude that some roses are red?\\nanalysis1: use formal logic rules\\nanalysis2: use everyday reasoning\\nanalysis3: use examples to test the conclusion\\ndo all the three approaches give me the same results?\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatGoogleGenerativeAI] [4.61s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"Yes, all three approaches should lead you to the same conclusion: **no, we cannot conclude that some roses are red.**\\n\\nLet's analyze each approach:\\n\\n**Analysis 1: Formal Logic Rules (Syllogistic Logic)**\\n\\n*   **Premise 1:** All roses are flowers. (All R are F)\\n*   **Premise 2:** Some flowers are red. (Some F are Red)\\n*   **Conclusion:** Some roses are red. (Some R are Red)\\n\\nThis is a classic example of a syllogism that is **invalid**.  The \\\"middle term\\\" (Flowers) is not \\\"distributed\\\" in either premise.  To be distributed, a term must refer to *all* members of the category.  Premise 1 says *all* roses are flowers, so it distributes roses. Premise 2 says *some* flowers are red, so it does not distribute flowers.\\n\\nBecause the middle term (Flowers) is not distributed, we can't validly link roses and red.\\n\\n**Analysis 2: Everyday Reasoning**\\n\\nThink about it this way: Just because all roses are flowers, and *some* flowers are red, doesn't mean the red flowers *have* to be roses. The red flowers could be tulips, or carnations, or any other type of flower.\\n\\nTherefore, you can't jump to the conclusion that *some* roses must be red. It's a possibility, but not a certainty.\\n\\n**Analysis 3: Use Examples to Test the Conclusion**\\n\\nLet's create a scenario:\\n\\n*   **Roses:**  We have 10 roses, all of which are white.\\n*   **Flowers:** We have 10 roses (all white) + 5 tulips (3 red, 2 yellow).\\n*   **Red things:** We have 3 red tulips.\\n\\nIn this scenario:\\n\\n*   All roses are flowers (True).\\n*   Some flowers are red (True, the tulips).\\n*   Are some roses red? (False, all the roses are white).\\n\\nThis example demonstrates that the conclusion is not necessarily true. The premise can be true, and the conclusion false. This proves that the reasoning is invalid.\\n\\n**Consistency:**\\n\\nAll three methods arrive at the same answer: we cannot conclude that some roses are red. The premises can be true, while the conclusion is false. The syllogism is invalid.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"STOP\",\n",
            "          \"safety_ratings\": []\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"Yes, all three approaches should lead you to the same conclusion: **no, we cannot conclude that some roses are red.**\\n\\nLet's analyze each approach:\\n\\n**Analysis 1: Formal Logic Rules (Syllogistic Logic)**\\n\\n*   **Premise 1:** All roses are flowers. (All R are F)\\n*   **Premise 2:** Some flowers are red. (Some F are Red)\\n*   **Conclusion:** Some roses are red. (Some R are Red)\\n\\nThis is a classic example of a syllogism that is **invalid**.  The \\\"middle term\\\" (Flowers) is not \\\"distributed\\\" in either premise.  To be distributed, a term must refer to *all* members of the category.  Premise 1 says *all* roses are flowers, so it distributes roses. Premise 2 says *some* flowers are red, so it does not distribute flowers.\\n\\nBecause the middle term (Flowers) is not distributed, we can't validly link roses and red.\\n\\n**Analysis 2: Everyday Reasoning**\\n\\nThink about it this way: Just because all roses are flowers, and *some* flowers are red, doesn't mean the red flowers *have* to be roses. The red flowers could be tulips, or carnations, or any other type of flower.\\n\\nTherefore, you can't jump to the conclusion that *some* roses must be red. It's a possibility, but not a certainty.\\n\\n**Analysis 3: Use Examples to Test the Conclusion**\\n\\nLet's create a scenario:\\n\\n*   **Roses:**  We have 10 roses, all of which are white.\\n*   **Flowers:** We have 10 roses (all white) + 5 tulips (3 red, 2 yellow).\\n*   **Red things:** We have 3 red tulips.\\n\\nIn this scenario:\\n\\n*   All roses are flowers (True).\\n*   Some flowers are red (True, the tulips).\\n*   Are some roses red? (False, all the roses are white).\\n\\nThis example demonstrates that the conclusion is not necessarily true. The premise can be true, and the conclusion false. This proves that the reasoning is invalid.\\n\\n**Consistency:**\\n\\nAll three methods arrive at the same answer: we cannot conclude that some roses are red. The premises can be true, while the conclusion is false. The syllogism is invalid.\",\n",
            "            \"response_metadata\": {\n",
            "              \"prompt_feedback\": {\n",
            "                \"block_reason\": 0,\n",
            "                \"safety_ratings\": []\n",
            "              },\n",
            "              \"finish_reason\": \"STOP\",\n",
            "              \"safety_ratings\": []\n",
            "            },\n",
            "            \"type\": \"ai\",\n",
            "            \"id\": \"run--690cdf27-1fe0-409a-942e-2fc10a529f95-0\",\n",
            "            \"usage_metadata\": {\n",
            "              \"input_tokens\": 78,\n",
            "              \"output_tokens\": 514,\n",
            "              \"total_tokens\": 592,\n",
            "              \"input_token_details\": {\n",
            "                \"cache_read\": 0\n",
            "              }\n",
            "            },\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"prompt_feedback\": {\n",
            "      \"block_reason\": 0,\n",
            "      \"safety_ratings\": []\n",
            "    }\n",
            "  },\n",
            "  \"run\": null,\n",
            "  \"type\": \"LLMResult\"\n",
            "}\n",
            "Yes, all three approaches should lead you to the same conclusion: **no, we cannot conclude that some roses are red.**\n",
            "\n",
            "Let's analyze each approach:\n",
            "\n",
            "**Analysis 1: Formal Logic Rules (Syllogistic Logic)**\n",
            "\n",
            "*   **Premise 1:** All roses are flowers. (All R are F)\n",
            "*   **Premise 2:** Some flowers are red. (Some F are Red)\n",
            "*   **Conclusion:** Some roses are red. (Some R are Red)\n",
            "\n",
            "This is a classic example of a syllogism that is **invalid**.  The \"middle term\" (Flowers) is not \"distributed\" in either premise.  To be distributed, a term must refer to *all* members of the category.  Premise 1 says *all* roses are flowers, so it distributes roses. Premise 2 says *some* flowers are red, so it does not distribute flowers.\n",
            "\n",
            "Because the middle term (Flowers) is not distributed, we can't validly link roses and red.\n",
            "\n",
            "**Analysis 2: Everyday Reasoning**\n",
            "\n",
            "Think about it this way: Just because all roses are flowers, and *some* flowers are red, doesn't mean the red flowers *have* to be roses. The red flowers could be tulips, or carnations, or any other type of flower.\n",
            "\n",
            "Therefore, you can't jump to the conclusion that *some* roses must be red. It's a possibility, but not a certainty.\n",
            "\n",
            "**Analysis 3: Use Examples to Test the Conclusion**\n",
            "\n",
            "Let's create a scenario:\n",
            "\n",
            "*   **Roses:**  We have 10 roses, all of which are white.\n",
            "*   **Flowers:** We have 10 roses (all white) + 5 tulips (3 red, 2 yellow).\n",
            "*   **Red things:** We have 3 red tulips.\n",
            "\n",
            "In this scenario:\n",
            "\n",
            "*   All roses are flowers (True).\n",
            "*   Some flowers are red (True, the tulips).\n",
            "*   Are some roses red? (False, all the roses are white).\n",
            "\n",
            "This example demonstrates that the conclusion is not necessarily true. The premise can be true, and the conclusion false. This proves that the reasoning is invalid.\n",
            "\n",
            "**Consistency:**\n",
            "\n",
            "All three methods arrive at the same answer: we cannot conclude that some roses are red. The premises can be true, while the conclusion is false. The syllogism is invalid.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Images- Images to Text"
      ],
      "metadata": {
        "id": "tHFkBK-7FqyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "vEzBPvWSEvP3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1461a28f-e5aa-46cf-e4d5-7a78e5e42bd1"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "4Lw2JiAmF3ex"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('GEMINI_API_KEY')\n",
        "genai.configure(api_key=api_key)"
      ],
      "metadata": {
        "id": "9PMtxKFvF-7Q"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai pillow"
      ],
      "metadata": {
        "id": "0EzXC47pGYlQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        },
        "outputId": "26d0a9be-c2ab-4de9-d6f8-489878f5183d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
            "  Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.28.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.187.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.43.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.12.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.11.12)\n",
            "Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
            "Installing collected packages: google-ai-generativelanguage\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.9.0\n",
            "    Uninstalling google-ai-generativelanguage-0.9.0:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.9.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-google-genai 3.2.0 requires google-ai-generativelanguage<1.0.0,>=0.9.0, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.6.15\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "ed7687105a664abcbe415a5813d9cf30"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image as PILImage # Alias PIL.Image to avoid name conflict\n",
        "\n",
        "def generate_image_caption(image_path):\n",
        "  if image_path:\n",
        "    # Use PILImage.open() to open the image\n",
        "    image = PILImage.open(image_path)\n",
        "    model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "    response = model.generate_content(['Describe this image in details', image])\n",
        "    return response.text\n",
        "  else:\n",
        "    return 'No Image proved'\n",
        "image_path = '/content/DOG.jpg'\n",
        "caption = generate_image_caption(image_path)\n",
        "print(caption)"
      ],
      "metadata": {
        "id": "v92-VDNpGUGn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "ec1c34c4-84e7-4e69-bc38-c101adf5cae4"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This image features an adorable **Yellow Labrador Retriever puppy** sitting attentively, filling the majority of the frame.\n",
            "\n",
            "Here's a detailed breakdown:\n",
            "\n",
            "**Subject:**\n",
            "*   **Breed & Age:** It's a very young puppy, clearly identifiable as a Yellow Labrador Retriever due to its broad head, floppy ears, and soft, short coat.\n",
            "*   **Color:** The puppy's fur is a lovely creamy yellow or light tan color, with some areas like the chest and inner legs appearing slightly lighter.\n",
            "*   **Pose:** The puppy is seated upright, facing directly towards the viewer. Its front paws are neatly placed together, and its hind legs are tucked underneath its body.\n",
            "*   **Facial Features:**\n",
            "    *   **Eyes:** It has dark, round, and alert eyes that are looking straight into the camera, giving it an intelligent and curious expression.\n",
            "    *   **Nose:** The nose is dark, likely black, and appears slightly moist.\n",
            "    *   **Mouth:** Its mouth is open just enough to reveal a portion of its pink tongue, which is hanging slightly out to the right (from the puppy's perspective), conveying a sense of happiness, playfulness, or panting.\n",
            "    *   **Ears:** Its signature Labrador ears are floppy and set wide on its head, with rounded tips, resting against its cheeks.\n",
            "*   **Expression:** The overall expression is one of endearing cuteness, happiness, and innocence, largely due to its bright eyes and visible tongue.\n",
            "\n",
            "**Setting & Background:**\n",
            "*   **Foreground (Surface):** The puppy is sitting on a textured, muted green surface, which appears to be a soft blanket, towel, or thick fabric. There are visible folds and slight undulations in the fabric, creating subtle shadows and highlights.\n",
            "*   **Background:** The background is a soft, out-of-focus blur of vibrant green foliage. This \"bokeh\" effect effectively isolates the puppy, making it the sole focal point. The greens range from lighter, almost yellowish-green in some areas to deeper, richer greens, suggesting natural leaves and plant life in an outdoor setting.\n",
            "\n",
            "**Lighting & Atmosphere:**\n",
            "*   **Lighting:** The lighting appears to be natural and soft, likely ambient outdoor light. There are gentle highlights on the puppy's fur, particularly on its head, ears, and back, suggesting the light source is slightly from above and to the right. Shadows are soft, adding definition without being harsh.\n",
            "*   **Overall Mood:** The image exudes warmth, charm, and pure adorableness. The bright eyes and playful tongue contribute to a cheerful and heartwarming atmosphere.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nmasX11wJu1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94bc1f6a"
      },
      "source": [
        "for m in genai.list_models():\n",
        "  print(f'{m.name}: {m.supported_generation_methods}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model evaluation Benchmarks"
      ],
      "metadata": {
        "id": "k2KdQfKRLpLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Benchmark for text\n",
        "# BLEU: Bilingual evaluation understudy"
      ],
      "metadata": {
        "id": "iyQmczr6NwTb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rogue\n",
        "#### recall oriented understudy for gisting evaluation"
      ],
      "metadata": {
        "id": "doX32LS2PvIn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hXPnPhvZLtYm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}